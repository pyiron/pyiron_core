{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a3828e-2e58-495c-8577-42137d640fc6",
   "metadata": {},
   "source": [
    "# Demo for automated computation of binary phase diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c16662a-ddf2-4329-85d5-7ae8419933ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow.graph import gui, base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9288759-db5b-42c9-a4bf-7b02d33455b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc605835087a4cd29f8727c0120a0f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3774f4044ee6472f82b0cd50b249b193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Output(layout=Layout(width='400px')), Tab(children=(ReactFlowWidget(layout=Layou…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = gui.PyironFlow([\"water\"]) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70bf4b-2872-4b57-abbd-e4ae0ce76ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = pr.create.job.Lammps('water_equilibration', delete_existing_job = True)\n",
    "\n",
    "solvated_electrode.add_tag(selective_dynamics=[True, True, True])\n",
    "solvated_electrode.selective_dynamics[solvated_electrode.select_index(\"Al\")] = [False, False, False]\n",
    "\n",
    "epsilon = 0.102\n",
    "sigma = 3.188\n",
    "water_potential = pandas.DataFrame({\n",
    "    'Name': ['H2O_tip3p'],\n",
    "    'Filename': [[]],\n",
    "    'Model': [\"TIP3P\"],\n",
    "    'Species': [['H','O','Al']],\n",
    "    'Config': [[\n",
    "    '# @potential_species H_O  ### species in potential\\n',\n",
    "     '# W.L. Jorgensen',\n",
    "     'The Journal of Chemical Physics 79',\n",
    "     '926 (1983); https://doi.org/10.1063/1.445869 \\n',\n",
    "     '#\\n',\n",
    "     '\\n',\n",
    "     'units      real\\n',\n",
    "     'dimension  3\\n',\n",
    "     'atom_style full\\n',\n",
    "     '\\n',\n",
    "     '# create groups ###\\n',\n",
    "     'group O type 2\\n',\n",
    "     'group H type 1\\n',\n",
    "     'group Al type 3\\n',\n",
    "     '\\n',\n",
    "     '## set charges - beside manually ###\\n',\n",
    "     'set group O charge -0.830\\n',\n",
    "     'set group H charge 0.415\\n',\n",
    "     'set group Al charge 0.2\\n',           \n",
    "     '\\n',\n",
    "     '### TIP3P Potential Parameters ###\\n',\n",
    "     'pair_style lj/cut/coul/long 10.0\\n',\n",
    "     'pair_coeff * * 0.000 0.000 \\n',\n",
    "     'pair_coeff 2 2 0.102 3.188 \\n',\n",
    "     'pair_coeff 2 3 {:.4} {:.4} \\n'.format(epsilon, sigma),      \n",
    "     'bond_style  harmonic\\n',\n",
    "     'bond_coeff  1 450 0.9572\\n',\n",
    "     'angle_style harmonic\\n',\n",
    "     'angle_coeff 1 55 104.52\\n',\n",
    "     'kspace_style pppm 1.0e-5   # final npt relaxation\\n',\n",
    "     '\\n']]})\n",
    "\n",
    "j.structure = solvated_electrode\n",
    "j.potential = water_potential\n",
    "j.calc_md(temperature=300)   \n",
    "\n",
    "j.run(run_mode='queue', delete_existing_job=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28622ae8-25a6-427c-8db6-cdcbe3b109cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056dfa54-bb3c-4814-a3d9-f48307315802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pyiron_database.instance_database.node.store_node_outputs(node: pyiron_workflow.simple_workflow.Node) -> str>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyiron_database.instance_database as idb\n",
    "from pyiron_nodes.math import Sin\n",
    "\n",
    "sin = Sin(3)\n",
    "\n",
    "idb.store_node_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb8c3db-a958-44d2-8826-795ba68ab8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding macro node phonopy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4d822d8d8a42e29bd6a745461cc024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Output(layout=Layout(width='400px')), Tab(children=(ReactFlowWidget(layout=Layou…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = gui.PyironFlow([\"phonopy\", \"show_code\", \"phonopy_macro\", \"phonopy_free_energy\", \"elastic\", \"elastic_macro\", \"elastic_macro\"]) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577afd28-8ab6-4084-9395-567485fe4493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding macro node phonopy\n",
      "Adding macro node ComputeElasticConstantsMacro\n",
      "Adding macro node CubicBulkCell\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b814b2f33cc641c588f98882d0bfe76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Output(layout=Layout(width='400px')), Tab(children=(ReactFlowWidget(layout=Layou…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding node ComputeElasticConstantsMacro\n"
     ]
    }
   ],
   "source": [
    "pf = gui.PyironFlow([\"phonopy\", \"show_code\", \"phonopy_macro\", \"phonopy_free_energy\", \"elastic\", \"elastic_macro\", \"elastic_macro2\"]) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c6366f-8acc-4516-8426-8509d1d36ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.atomistic.property.elastic import ComputeElasticConstants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffb3b91e-c367-4c43-84b2-8e7eac71183e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m wf\u001b[38;5;241m.\u001b[39mnode \u001b[38;5;241m=\u001b[39m Node()\n\u001b[1;32m      6\u001b[0m wf\u001b[38;5;241m.\u001b[39msin \u001b[38;5;241m=\u001b[39m pn\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mSin(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mwf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, wf\u001b[38;5;241m.\u001b[39mnode\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/simple_workflow.py:1187\u001b[0m, in \u001b[0;36mWorkflow.run\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 1187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwf_graph_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_wf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/wf_graph_tools.py:397\u001b[0m, in \u001b[0;36mrun_wf\u001b[0;34m(wf, debug)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_wf\u001b[39m(wf, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 397\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mget_graph_from_wf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     variable_nodes \u001b[38;5;241m=\u001b[39m _get_variable_nodes(graph)\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(graph\u001b[38;5;241m.\u001b[39mnodes):\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/wf_graph_tools.py:274\u001b[0m, in \u001b[0;36mget_graph_from_wf\u001b[0;34m(wf)\u001b[0m\n\u001b[1;32m    271\u001b[0m edges \u001b[38;5;241m=\u001b[39m _filter_and_flatten_nested_dict_keys(_get_edges(wf), keys_to_keep)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# add edges for non-default inputs\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[43mget_nodes_from_wf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/import_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/target_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/target_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m nodes_non_default_inp_param \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/wf_graph_tools.py:153\u001b[0m, in \u001b[0;36mget_nodes_from_wf\u001b[0;34m(wf, keys_to_keep)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_nodes_from_wf\u001b[39m(wf, keys_to_keep\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/label\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/import_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    152\u001b[0m     key_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata__label\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata__import_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport_path\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 153\u001b[0m     nodes_dict \u001b[38;5;241m=\u001b[39m _filter_and_flatten_nested_dict_keys(\u001b[43m_get_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwf\u001b[49m\u001b[43m)\u001b[49m, keys_to_keep)\n\u001b[1;32m    154\u001b[0m     nodes_dict \u001b[38;5;241m=\u001b[39m _rename_keys(nodes_dict, key_mapping)\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nodes_dict\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyironflow/wf_extensions.py:193\u001b[0m, in \u001b[0;36mget_nodes\u001b[0;34m(wf)\u001b[0m\n\u001b[1;32m    190\u001b[0m nodes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (key, node) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(wf\u001b[38;5;241m.\u001b[39m_nodes\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# print(node_dict)\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     nodes\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_node_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nodes\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyironflow/wf_extensions.py:160\u001b[0m, in \u001b[0;36mget_node_dict\u001b[0;34m(node, id_num, key)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# TODO: set to None if it contains an edge (include connected parameter)\u001b[39;00m\n\u001b[1;32m    156\u001b[0m target_types \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (t \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuiltins.NoneType\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m connected \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t, connected \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m], is_connected)\n\u001b[1;32m    159\u001b[0m ]\n\u001b[0;32m--> 160\u001b[0m import_path \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# print('import_path: ', import_path)\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: node\u001b[38;5;241m.\u001b[39mlabel,\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msourcePosition\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    186\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'function'"
     ]
    }
   ],
   "source": [
    "from pyiron_workflow import Workflow, Node\n",
    "import pyiron_nodes as pn\n",
    "\n",
    "wf = Workflow(\"test\")\n",
    "wf.node = Node()\n",
    "wf.sin = pn.math.Sin(x=3)\n",
    "\n",
    "wf.run(), wf.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eed21f34-7708-4045-a334-032f0bb56c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using calculator: <pyiron_workflow.simple_workflow.Node object at 0x199e15c70>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'InputElasticTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m engine \u001b[38;5;241m=\u001b[39m M3GNet()\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m     51\u001b[0m calculator \u001b[38;5;241m=\u001b[39m StaticEnergy(bulk, engine\u001b[38;5;241m=\u001b[39mengine) \u001b[38;5;66;03m#.run()\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mComputeElasticConstants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbulk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m    \n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/simple_workflow.py:665\u001b[0m, in \u001b[0;36mNode.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m     out \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    660\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(p\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m returned_ports)\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(return_tuple) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m returned_ports[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    663\u001b[0m     )\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 665\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_set_values(out)\n\u001b[1;32m    667\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/simple_workflow.py:710\u001b[0m, in \u001b[0;36mNode._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;66;03m# print(\"node_run: \", self.label, self.kwargs, self._func)\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 46\u001b[0m, in \u001b[0;36mComputeElasticConstants\u001b[0;34m(structure, engine, input_elastic_tensor)\u001b[0m\n\u001b[1;32m     34\u001b[0m wf\u001b[38;5;241m.\u001b[39menergies \u001b[38;5;241m=\u001b[39m iterate(\n\u001b[1;32m     35\u001b[0m     node\u001b[38;5;241m=\u001b[39mwf\u001b[38;5;241m.\u001b[39mcalculator,\n\u001b[1;32m     36\u001b[0m     values\u001b[38;5;241m=\u001b[39mwf\u001b[38;5;241m.\u001b[39mstructures\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mstructures,\n\u001b[1;32m     37\u001b[0m     input_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructure\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m wf\u001b[38;5;241m.\u001b[39melastic_constants \u001b[38;5;241m=\u001b[39m AnalyseStructures(\n\u001b[1;32m     41\u001b[0m     energies\u001b[38;5;241m=\u001b[39mwf\u001b[38;5;241m.\u001b[39menergies,\n\u001b[1;32m     42\u001b[0m     job_names\u001b[38;5;241m=\u001b[39mwf\u001b[38;5;241m.\u001b[39mstructures\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mjob_names,\n\u001b[1;32m     43\u001b[0m     analysis\u001b[38;5;241m=\u001b[39mwf\u001b[38;5;241m.\u001b[39msymmetry,\n\u001b[1;32m     44\u001b[0m     parameters\u001b[38;5;241m=\u001b[39minput_elastic_tensor,\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m elastic_constants \u001b[38;5;241m=\u001b[39m \u001b[43mwf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menergies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m elastic_constants\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/simple_workflow.py:715\u001b[0m, in \u001b[0;36mNode.pull\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpull\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workflow \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 715\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mwf_graph_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpull_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;66;03m# self._workflow.run()\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    718\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/wf_graph_tools.py:430\u001b[0m, in \u001b[0;36mpull_node\u001b[0;34m(wf, node_label)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpull_node\u001b[39m(wf: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorkflow\u001b[39m\u001b[38;5;124m\"\u001b[39m, node_label: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    422\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    Pull a node from the workflow graph and run it. Execute only nodes that\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    are required as input to run the node.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m        node_label (str): The label of the node to pull.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mget_graph_from_wf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     node_labels \u001b[38;5;241m=\u001b[39m _get_node_labels(graph)\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m node_labels:\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/wf_graph_tools.py:318\u001b[0m, in \u001b[0;36mget_graph_from_wf\u001b[0;34m(wf)\u001b[0m\n\u001b[1;32m    313\u001b[0m nodes \u001b[38;5;241m=\u001b[39m _rename_keys(nodes_non_default_inp_param \u001b[38;5;241m+\u001b[39m nodes, key_mapping\u001b[38;5;241m=\u001b[39mkey_mapping)\n\u001b[1;32m    315\u001b[0m graph \u001b[38;5;241m=\u001b[39m WorkflowGraph(\n\u001b[1;32m    316\u001b[0m     nodes\u001b[38;5;241m=\u001b[39m_nodes_from_dict(nodes), edges\u001b[38;5;241m=\u001b[39m_edges_from_dict(edges), label\u001b[38;5;241m=\u001b[39mwf\u001b[38;5;241m.\u001b[39mlabel\n\u001b[1;32m    317\u001b[0m )\n\u001b[0;32m--> 318\u001b[0m sorted_graph \u001b[38;5;241m=\u001b[39m \u001b[43mtopological_sort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sorted_graph\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/wf_graph_tools.py:231\u001b[0m, in \u001b[0;36mtopological_sort\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtopological_sort\u001b[39m(graph: WorkflowGraph):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Kahn's algorithm for topological sorting\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# Create a graph and in-degree count for each node\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     sort_graph \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m--> 231\u001b[0m     edges \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_to_integer_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(graph\u001b[38;5;241m.\u001b[39mnodes))\n\u001b[1;32m    234\u001b[0m     in_degree \u001b[38;5;241m=\u001b[39m {node: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes}\n",
      "File \u001b[0;32m~/git_libs/pyiron_core2/pyiron_workflow/wf_graph_tools.py:164\u001b[0m, in \u001b[0;36m_convert_to_integer_representation\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    160\u001b[0m node_to_index \u001b[38;5;241m=\u001b[39m {node[\u001b[38;5;241m0\u001b[39m]: index \u001b[38;5;28;01mfor\u001b[39;00m index, node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(graph\u001b[38;5;241m.\u001b[39mnodes)}\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Convert edge list to integer representation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m integer_edges \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 164\u001b[0m     (\u001b[43mnode_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, node_to_index[edge[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m edge \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39medges\n\u001b[1;32m    166\u001b[0m ]\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m integer_edges\n",
      "\u001b[0;31mKeyError\u001b[0m: 'InputElasticTensor'"
     ]
    }
   ],
   "source": [
    "from pyiron_workflow import as_macro_node, as_function_node, Node\n",
    "from pyiron_nodes.atomistic.structure.build import Bulk\n",
    "from pyiron_nodes.atomistic.engine.ase import M3GNet\n",
    "from pyiron_nodes.atomistic.calculator.ase import StaticEnergy, Static\n",
    "from pyiron_nodes.atomistic.property.elastic import InputElasticTensor, SymmetryAnalysis, GenerateStructures, AnalyseStructures\n",
    "\n",
    "@as_function_node\n",
    "def ComputeElasticConstants(\n",
    "    structure,\n",
    "    engine,\n",
    "    # calculator: Node = None,    \n",
    "    input_elastic_tensor: InputElasticTensor = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the elastic constants of a structure using an ASE calculator.\n",
    "    \"\"\"\n",
    "    from pyiron_workflow import Workflow\n",
    "    from pyiron_nodes.controls import iterate, IterToDataFrame, Print\n",
    "    from pyiron_nodes.atomistic.calculator.ase import StaticEnergy, Static\n",
    "    from pyiron_nodes.atomistic.property.phonons import GetFreeEnergy\n",
    "\n",
    "    wf = Workflow(\"elastic_constants\")\n",
    "    if input_elastic_tensor is None:\n",
    "        input_elastic_tensor = InputElasticTensor()\n",
    "    # wf.print = Print(f\"calculator: {calculator}\")\n",
    "    # wf.calculator = StaticEnergy(structure=structure, engine=engine)\n",
    "    wf.calculator = GetFreeEnergy(structure=structure, engine=engine)\n",
    "    print(f\"Using calculator: {wf.calculator}\")\n",
    "    # print(f\"Input calculator: {calculator}\")\n",
    "    wf.symmetry = SymmetryAnalysis(structure=structure, parameters=input_elastic_tensor)\n",
    "    wf.structures = GenerateStructures(\n",
    "        structure=structure, analysis=wf.symmetry, parameters=input_elastic_tensor\n",
    "    )\n",
    "    wf.energies = iterate(\n",
    "        node=wf.calculator,\n",
    "        values=wf.structures.outputs.structures,\n",
    "        input_label=\"structure\",\n",
    "    )\n",
    "\n",
    "    wf.elastic_constants = AnalyseStructures(\n",
    "        energies=wf.energies,\n",
    "        job_names=wf.structures.outputs.job_names,\n",
    "        analysis=wf.symmetry,\n",
    "        parameters=input_elastic_tensor,\n",
    "    )\n",
    "    elastic_constants = wf.energies.pull()\n",
    "    return elastic_constants\n",
    "\n",
    "bulk = Bulk(\"Al\", cubic=True).run()\n",
    "engine = M3GNet().run()\n",
    "calculator = StaticEnergy(bulk, engine=engine) #.run()\n",
    "ComputeElasticConstants(bulk, engine, calculator).run()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af252edd-3dec-4ce9-ab4e-09bfe5432481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joerg/miniforge3/envs/intel12/lib/python3.12/site-packages/matgl/apps/pes.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.element_refs = AtomRef(property_offset=torch.tensor(element_refs, dtype=matgl.float_th))\n",
      "/Users/joerg/miniforge3/envs/intel12/lib/python3.12/site-packages/matgl/apps/pes.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"data_mean\", torch.tensor(data_mean, dtype=matgl.float_th))\n",
      "/Users/joerg/miniforge3/envs/intel12/lib/python3.12/site-packages/matgl/apps/pes.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"data_std\", torch.tensor(data_std, dtype=matgl.float_th))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyiron_workflow.simple_workflow.Node object at 0x194e31640>\n",
      "Error getting hash for node: GetFreeEnergy maximum recursion depth exceeded\n",
      "copy node:  GetFreeEnergy None\n",
      "Calculating free energy at 300 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joerg/miniforge3/envs/intel12/lib/python3.12/site-packages/spglib/spglib.py:115: DeprecationWarning: dict interface (SpglibDataset['number']) is deprecated.Use attribute interface ({self.__class__.__name__}.{key}) instead\n",
      "  warnings.warn(\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-12.62283435]), 'entropy': array([145.58394598]), 'heat_capacity': array([96.10179911])}\n",
      "Free energy: -12.622834348976632 eV\n",
      "Error getting hash for node: calculator maximum recursion depth exceeded\n",
      "copy node:  calculator None\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-12.62283435]), 'entropy': array([145.58394598]), 'heat_capacity': array([96.10179911])}\n",
      "Free energy: -12.622834348976632 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-11.57095222]), 'entropy': array([142.34089824]), 'heat_capacity': array([95.84778349])}\n",
      "Free energy: -11.570952222607874 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-12.09915514]), 'entropy': array([143.96727041]), 'heat_capacity': array([95.97730898])}\n",
      "Free energy: -12.099155141040244 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-13.1507523]), 'entropy': array([147.2178626]), 'heat_capacity': array([96.22343174])}\n",
      "Free energy: -13.150752300052268 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-13.69176155]), 'entropy': array([148.89649887]), 'heat_capacity': array([96.34416208])}\n",
      "Free energy: -13.691761552666597 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-11.92291448]), 'entropy': array([143.42416855]), 'heat_capacity': array([95.93450345])}\n",
      "Free energy: -11.922914483538875 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-12.27388976]), 'entropy': array([144.50625943]), 'heat_capacity': array([96.01925839])}\n",
      "Free energy: -12.273889760954768 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-12.97422613]), 'entropy': array([146.67107652]), 'heat_capacity': array([96.18316424])}\n",
      "Free energy: -12.974226131818785 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-13.32833491]), 'entropy': array([147.76845148]), 'heat_capacity': array([96.26344501])}\n",
      "Free energy: -13.328334913980633 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-14.5786063]), 'entropy': array([152.10951746]), 'heat_capacity': array([96.10254096])}\n",
      "Free energy: -14.578606296405589 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-14.58661029]), 'entropy': array([152.12919316]), 'heat_capacity': array([96.10923378])}\n",
      "Free energy: -14.586610285541344 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-14.30955964]), 'entropy': array([150.95491357]), 'heat_capacity': array([95.8610958])}\n",
      "Free energy: -14.30955963976287 eV\n",
      "Calculating free energy at 300 K\n",
      "Free energy calculated for temperature: 300 K:  {'temperatures': array([300.]), 'free_energy': array([-17.13670675]), 'entropy': array([159.92934714]), 'heat_capacity': array([96.29898637])}\n",
      "Free energy: -17.136706752394797 eV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutputElasticAnalysis(strain_energy=[[(-0.005, -11.570952222607874), (-0.0025, -12.099155141040244), (0.0, -12.622834348976632), (0.0024999999999999996, -13.150752300052268), (0.005, -13.691761552666597)], [(-0.005, -11.922914483538875), (-0.0025, -12.273889760954768), (0.0, -12.622834348976632), (0.0024999999999999996, -12.974226131818785), (0.005, -13.328334913980633)], [(-0.005, -14.578606296405589), (-0.0025, -14.586610285541344), (0.0, -12.622834348976632), (0.0024999999999999996, -14.30955963976287), (0.005, -17.136706752394797)]], C=array([[    68.15210251,   -308.34768129,   -308.34768129,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       [  -308.34768129,     68.15210251,   -308.34768129,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       [  -308.34768129,   -308.34768129,     68.15210251,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       [     0.        ,      0.        ,      0.        ,\n",
       "        -42672.20130306,      0.        ,      0.        ],\n",
       "       [     0.        ,      0.        ,      0.        ,\n",
       "             0.        , -42672.20130306,      0.        ],\n",
       "       [     0.        ,      0.        ,      0.        ,\n",
       "             0.        ,      0.        , -42672.20130306]]), A2=array([-5.13560660e+00, -1.49918288e+00, -1.59803359e+03]), C_eigval=array([   376.4997838 ,   -548.54326008,    376.4997838 , -42672.20130306,\n",
       "       -42672.20130306, -42672.20130306]), C_eigvec=array([[ 0.81649658, -0.57735027,  0.47611315,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.40824829, -0.57735027, -0.8125017 ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.40824829, -0.57735027,  0.33638855,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ]]), BV=-182.8477533602154, GV=-25528.02082507734, EV=-1611.0125230913502, nuV=-0.9684461922424323, S=array([[ 1.16302592e-03, -1.49301810e-03, -1.49301810e-03,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00],\n",
       "       [-1.49301810e-03,  1.16302592e-03, -1.49301810e-03,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00],\n",
       "       [-1.49301810e-03, -1.49301810e-03,  1.16302592e-03,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00],\n",
       "       [-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -2.34344601e-05, -0.00000000e+00, -0.00000000e+00],\n",
       "       [-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -2.34344601e-05, -0.00000000e+00],\n",
       "       [-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -2.34344601e-05]]), BR=-182.84775336021534, GR=473.75974097226754, ER=10425.199933340973, nuR=10.002623304320863, BH=-182.84775336021536, GH=-12527.130542052535, EH=-1576.593251937566, nuH=-0.9370728497382114, AVR=103.78186959401356, energy_0=-12.622834348976632)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from pyiron_nodes.controls import iterate, IterToDataFrame, Print\n",
    "from pyiron_nodes.atomistic.calculator.ase import StaticEnergy, Static\n",
    "from pyiron_nodes.atomistic.property.phonons import GetFreeEnergy\n",
    "\n",
    "from pyiron_workflow import as_macro_node, as_function_node, Node\n",
    "from pyiron_nodes.atomistic.structure.build import Bulk\n",
    "from pyiron_nodes.atomistic.engine.ase import M3GNet\n",
    "from pyiron_nodes.atomistic.calculator.ase import StaticEnergy, Static\n",
    "from pyiron_nodes.atomistic.property.elastic import InputElasticTensor, SymmetryAnalysis, GenerateStructures, AnalyseStructures\n",
    "\n",
    "structure = Bulk(\"Al\", cubic=True).run()\n",
    "engine = M3GNet().run()\n",
    "calculator = StaticEnergy(structure, engine=engine)\n",
    "calculator = GetFreeEnergy(structure=structure, engine=engine)\n",
    "parameters = InputElasticTensor(num_of_point=6)\n",
    "\n",
    "@as_function_node\n",
    "def elastic_constants(structure, calculator: Node, input_elastic_tensor:InputElasticTensor=None):\n",
    "    wf = Workflow(\"elastic_constants\")\n",
    "    if input_elastic_tensor is None:\n",
    "        input_elastic_tensor = InputElasticTensor().run()\n",
    "    wf.calculator = calculator \n",
    "    \n",
    "    wf.symmetry = SymmetryAnalysis(structure=structure, parameters=input_elastic_tensor)\n",
    "    wf.structures = GenerateStructures(\n",
    "        structure=structure, analysis=wf.symmetry, parameters=input_elastic_tensor\n",
    "    )\n",
    "    wf.energies = iterate(\n",
    "        node=wf.calculator,\n",
    "        values=wf.structures.outputs.structures,\n",
    "        input_label=\"structure\",\n",
    "    )\n",
    "    \n",
    "    wf.elastic_constants = AnalyseStructures(\n",
    "        energies=wf.energies,\n",
    "        job_names=wf.structures.outputs.job_names,\n",
    "        analysis=wf.symmetry,\n",
    "        parameters=input_elastic_tensor,\n",
    "    )\n",
    "    \n",
    "    elastic_constants = wf.elastic_constants.pull()\n",
    "    return elastic_constants\n",
    "\n",
    "print(calculator)\n",
    "node = elastic_constants(structure, calculator, parameters)\n",
    "node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa9fe1e-32cc-479d-9886-0a71260229ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pyiron_log:Not supported parameter used!\n",
      "DEBUG:pyiron_log:Not supported parameter used!\n"
     ]
    }
   ],
   "source": [
    "from phonopy import Phonopy\n",
    "from structuretoolkit.common import atoms_to_phonopy, phonopy_to_atoms\n",
    "\n",
    "from pyiron_nodes.atomistic.structure.build import CubicBulkCell\n",
    "\n",
    "Al = CubicBulkCell('Al', 3).run()\n",
    "phonopy = Phonopy(unitcell=atoms_to_phonopy(Al))\n",
    "phonopy.generate_displacements(distance=0.01, is_plusminus='auto', is_diagonal=True, is_trigonal=False, number_of_snapshots=None, random_seed=None, temperature=None, cutoff_frequency=None, max_distance=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a038a1b-20cc-4aa7-9be5-233779c6e43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThermalProperties(temperatures=array([], dtype=float64), free_energy=array([], dtype=float64), entropy=array([], dtype=float64), heat_capacity=array([], dtype=float64))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyiron_nodes.atomistic.property.phonons import ThermalProperties\n",
    "\n",
    "ThermalProperties().dataclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "797cd898-2884-4d5a-8e1a-f454194504eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThermalProperties(temperatures=[1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyiron_workflow import as_out_dataclass_node\n",
    "import numpy as np\n",
    "\n",
    "@as_out_dataclass_node\n",
    "class ThermalProperties:\n",
    "    from dataclasses import field\n",
    "\n",
    "    temperatures: list | np.ndarray = field(\n",
    "        default_factory=lambda: np.array([])\n",
    "    )\n",
    "\n",
    "ThermalProperties().dataclass(temperatures=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86dc29e-f83f-4b06-9897-8e5ae2e9c86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distance': 0.01,\n",
       " 'is_plusminus': 'auto',\n",
       " 'is_diagonal': True,\n",
       " 'is_trigonal': False,\n",
       " 'number_of_snapshots': None,\n",
       " 'random_seed': None,\n",
       " 'temperature': None,\n",
       " 'cutoff_frequency': None,\n",
       " 'max_distance': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyiron_nodes.atomistic.property.phonons import PhonopyParameters\n",
    "from dataclasses import asdict\n",
    "\n",
    "pp = PhonopyParameters().run()\n",
    "asdict(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5b9e7a-4a13-49ce-a433-8db90731665e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de03cc45138c4bab9253a1f7f6732046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c0bbfa69dd4bceb0ce39dd4f505467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Output(layout=Layout(width='400px')), Tab(children=(ReactFlowWidget(layout=Layou…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = gui.PyironFlow(['assyst',  'linearfit2', 'landau2']) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44320e3-e06c-478c-99b0-d2df07ec2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = gui.GUILayout()\n",
    "layout.flow_widget_height = 800\n",
    "\n",
    "# working: 'Workflow_4', 'experiment', 'assyst_linear_fit3', 'neighbors1', 'energy', 'murn4', 'db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd419c8-b698-45f7-9a1b-17ffc4a3d498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding macro node CubicBulkCell\n",
      "Adding macro node FitDiffPotential\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80da0c96f5774918911e7f82d81bdaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Output(layout=Layout(width='400px')), Tab(children=(ReactFlowWidget(layout=Layou…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = gui.PyironFlow(['Workflow_4', 'assyst_linear_fit3', 'macro_fit', 'bspline_test', 'bspline_test3', 'iter_test', 'descriptor'], gui_layout=layout) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffe9dcc2-1b25-4391-901b-fac551832eaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxx\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011a987-a4ec-4f5f-b713-cdef36c2eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_nodes as pn\n",
    "\n",
    "Al = pn.atomistic.structure.build.Bulk('Al')\n",
    "Al.inputs.name.value = \"Cu\"\n",
    "Al.inputs[\"name\"].value =\"Fe\"\n",
    "Al.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4db80d-47d3-4413-8c65-6b0e73bbdaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Tuple, List, Dict, Any\n",
    "from pyiron_workflow import Node\n",
    "from pyiron_workflow.simple_workflow import Data, Port, PORT_LABEL, PORT_DEFAULT, PORT_TYPE, PORT_VALUE\n",
    "\n",
    "\n",
    "### BEGIN: Helper function from previous answer with stricter checks\n",
    "class ReturnAnalysisError(Exception):\n",
    "    pass\n",
    "\n",
    "def analyze_function_code(func_str):\n",
    "    tree = ast.parse(func_str)\n",
    "    # Find the first function definition\n",
    "    func_node = next(node for node in tree.body if isinstance(node, ast.FunctionDef))\n",
    "    # Arguments\n",
    "    args_info = []\n",
    "    all_args = func_node.args.args\n",
    "    defaults = [None] * (len(all_args) - len(func_node.args.defaults)) + func_node.args.defaults\n",
    "    for arg, default in zip(all_args, defaults):\n",
    "        arg_name = arg.arg\n",
    "        arg_type = ast.unparse(arg.annotation) if arg.annotation else None\n",
    "        if default is not None:\n",
    "            try:\n",
    "                default_value = ast.literal_eval(default)\n",
    "            except Exception:\n",
    "                default_value = ast.unparse(default)\n",
    "        else:\n",
    "            default_value = None\n",
    "        args_info.append({\n",
    "            'name': arg_name,\n",
    "            'type': arg_type,\n",
    "            'default': default_value\n",
    "        })\n",
    "    # Return type annotation\n",
    "    return_type = ast.unparse(func_node.returns) if func_node.returns else None\n",
    "\n",
    "    # Extract return variable names from 'return' (with safety checks)\n",
    "    class ReturnVisitor(ast.NodeVisitor):\n",
    "        def __init__(self):\n",
    "            self.return_vars = []\n",
    "        def visit_Return(self, node):\n",
    "            if node.value is None:\n",
    "                self.return_vars.append(None)\n",
    "            elif isinstance(node.value, ast.Name):\n",
    "                self.return_vars.append(node.value.id)\n",
    "            elif isinstance(node.value, ast.Tuple):\n",
    "                names = []\n",
    "                for elt in node.value.elts:\n",
    "                    if isinstance(elt, ast.Name):\n",
    "                        names.append(elt.id)\n",
    "                    else:\n",
    "                        raise ReturnAnalysisError(\n",
    "                            f\"Invalid return variable: {ast.unparse(elt)}. Must return variable names, not expressions.\"\n",
    "                        )\n",
    "                self.return_vars.append(tuple(names))\n",
    "            else:\n",
    "                raise ReturnAnalysisError(\n",
    "                    f\"Invalid return value: {ast.unparse(node.value)}. Must return variable names, not expressions.\"\n",
    "                )\n",
    "    visitor = ReturnVisitor()\n",
    "    visitor.visit(func_node)\n",
    "    if len(visitor.return_vars) > 1:\n",
    "        raise ReturnAnalysisError(\"Function contains multiple 'return' statements, which is not supported.\")\n",
    "    return_vars = visitor.return_vars[0] if visitor.return_vars else None\n",
    "    return {\n",
    "        'function_name': func_node.name,\n",
    "        'arguments': args_info,\n",
    "        'return_type': return_type,\n",
    "        'returned_variables': return_vars\n",
    "    }\n",
    "### END: Helper function\n",
    "\n",
    "### The requested main function:\n",
    "def function_string_to_node(func_str):\n",
    "    # Analyze the function code to extract port specifications and return variable names\n",
    "    info = analyze_function_code(func_str)\n",
    "    arg_info = info['arguments']\n",
    "    return_type = info['return_type']\n",
    "    return_vars = info['returned_variables']\n",
    "    # Compose code string and function object\n",
    "    local_vars = {}\n",
    "    exec_globals = {\n",
    "        '__builtins__': __builtins__,\n",
    "        'Tuple': Tuple,\n",
    "        'List': List,\n",
    "        'Dict': Dict,\n",
    "        'Any': Any,\n",
    "    }\n",
    "    exec(func_str, exec_globals, local_vars)\n",
    "    fn = [v for k,v in local_vars.items() if callable(v)][0]  # Gets the defined function\n",
    "    \n",
    "    # Prepare inputs for Node\n",
    "    inputs = Data({\n",
    "        PORT_LABEL: [arg['name'] for arg in arg_info],\n",
    "        PORT_TYPE: [arg['type'] for arg in arg_info],\n",
    "        PORT_DEFAULT: [arg['default'] for arg in arg_info],\n",
    "        PORT_VALUE: [None] * len(arg_info),\n",
    "        \"ready\": [False] * len(arg_info)\n",
    "    }, attribute=Port)\n",
    "\n",
    "    # Prepare outputs for Node\n",
    "    if return_vars is None:\n",
    "        output_labels = []\n",
    "        output_types = []\n",
    "    elif isinstance(return_vars, str):\n",
    "        output_labels = [return_vars]\n",
    "        output_types = [return_type]\n",
    "    else:  # tuple of names\n",
    "        output_labels = list(return_vars)\n",
    "        # split return_type if it's a tuple type (e.g. Tuple[int,int])\n",
    "        # Otherwise just assign the same return_type to all outputs for lack of better info\n",
    "        if return_type and return_type.startswith('Tuple['):\n",
    "            inside = return_type[6:-1]\n",
    "            out_types = [s.strip() for s in inside.split(',')]\n",
    "            if len(out_types) == len(output_labels):\n",
    "                output_types = out_types\n",
    "            else:\n",
    "                output_types = [return_type] * len(output_labels)\n",
    "        else:\n",
    "            output_types = [return_type] * len(output_labels)\n",
    "    outputs = Data({\n",
    "        PORT_LABEL: output_labels,\n",
    "        PORT_TYPE: output_types,\n",
    "        PORT_VALUE: [None]*len(output_labels),\n",
    "        \"ready\": [False] * len(output_labels)\n",
    "    }, attribute=Port)\n",
    "    \n",
    "    node = Node(\n",
    "        func=fn,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        label=info['function_name'],\n",
    "        output_labels=output_labels if output_labels else None,\n",
    "        node_type=\"function_node\"\n",
    "    )\n",
    "    return node\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f902ff-97e7-42b4-8cb4-307d3ee6ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with an example\n",
    "\n",
    "func_str = '''\n",
    "def AddMultiply(x: float, y: int = 2) -> Tuple[float, float]:\n",
    "    z = x + y\n",
    "    w = x * y\n",
    "    return z, w\n",
    "'''\n",
    "n = function_string_to_node(func_str)\n",
    "n(x=3, y=2)\n",
    "n.outputs.z.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3112599-b72f-4eb3-8e66-0830d3969932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "PORT_LABEL = 'label'\n",
    "PORT_TYPE = 'type'\n",
    "PORT_DEFAULT = 'default'\n",
    "PORT_VALUE = 'value'\n",
    "\n",
    "class Port:\n",
    "    \"\"\"Holds the attributes of a single port.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        label: str,\n",
    "        type_: Optional[Any] = None,\n",
    "        default: Optional[Any] = None,\n",
    "        value: Optional[Any] = None\n",
    "    ) -> None:\n",
    "        self.label = label\n",
    "        self.type = type_\n",
    "        self.default = default\n",
    "        self.value = value\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f\"Port(label={self.label!r}, type={self.type!r}, \"\n",
    "                f\"default={self.default!r}, value={self.value!r})\")\n",
    "\n",
    "\n",
    "class Data:\n",
    "    \"\"\"Holds a set of Port objects, mapped by their label (as attributes).\"\"\"\n",
    "    def __init__(self, port_dict: Dict[str, List[Any]]) -> None:\n",
    "        # Determine number of ports:\n",
    "        primary_key = PORT_LABEL\n",
    "        labels = port_dict.get(primary_key, [])\n",
    "        # get the keys in port_dict that will be attributes of Port:\n",
    "        keys = list(port_dict.keys())\n",
    "        for i, label in enumerate(labels):\n",
    "            attrs = {}\n",
    "            for key in keys:\n",
    "                value_list = port_dict.get(key, [])\n",
    "                attrs[key] = value_list[i] if i < len(value_list) else None\n",
    "            # Create Port instance with unpacked dict and add it as attribute\n",
    "            self.__setattr__(label, Port(\n",
    "                label=attrs.get(PORT_LABEL),\n",
    "                type_=attrs.get(PORT_TYPE),\n",
    "                default=attrs.get(PORT_DEFAULT),\n",
    "                value=attrs.get(PORT_VALUE)\n",
    "            ))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        ports = [attr for attr in self.__dict__ if isinstance(getattr(self, attr), Port)]\n",
    "        return f\"Data({', '.join(ports)})\"\n",
    "\n",
    "\n",
    "# --- Example usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    input = Data({\n",
    "        PORT_LABEL: ['label_1', 'label_2'],\n",
    "        PORT_TYPE: ['int', 'float'],\n",
    "        PORT_DEFAULT: [0, 1.0],\n",
    "        PORT_VALUE: [None, None],\n",
    "    })\n",
    "    port_1 = input.label_1\n",
    "    print(port_1)              # Port(label='label_1', type='int', default=0, value=None)\n",
    "    print(port_1.label)        # 'label_1'\n",
    "    print(port_1.type)         # 'int'\n",
    "    print(port_1.default)      # 0\n",
    "    print(port_1.value)        # None\n",
    "\n",
    "    port_2 = input.label_2\n",
    "    print(port_2)              # Port(label='label_2', type='float', default=1.0, value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994930ff-cda5-4267-b49e-11997117e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import as_function_node, Workflow\n",
    "from pyiron_workflow.simple_workflow import _return_as_function_node\n",
    "\n",
    "\n",
    "@as_function_node\n",
    "def CodeToNode(code):\n",
    "    node = function_string_to_node(code)\n",
    "    return code\n",
    "\n",
    "\n",
    "wf = Workflow('CodeEditor')\n",
    "wf.add_multiply = CodeToNode(code=func_str)   \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5683f-b5cd-4ed7-acba-b77ebbd279d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin(x: float):\n",
    "    import numpy as np\n",
    "    sin = np.sin(x)\n",
    "    return sin\n",
    "\n",
    "_return_as_function_node(sin,'Sin', ['sin'], 'function_node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e39aa-963b-4426-981c-d6c534f7a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca76eb79-bff2-4936-bd7a-dc55fdaf5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "from scipy.interpolate import BSpline\n",
    "\n",
    "BSpline.design_matrix??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de52c2-91dd-4b8f-8ca2-578d51f3e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.atomistic.structure.calc import FitDiffPotential2\n",
    "\n",
    "FitDiffPotential2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41210da7-aafa-43cd-9ba3-97d17e62bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from pyiron_nodes.atomistic.ml_potentials.fitting.linearfit import (\n",
    "    ReadPickledDatasetAsDataframe,\n",
    ")\n",
    "from pyiron_nodes.math import Linspace, Divide, DotProduct\n",
    "from pyiron_nodes.atomistic.structure.calc import LinearInterpolationDescriptor\n",
    "from pyiron_nodes.dataframe import (\n",
    "    MergeDataFrames,\n",
    "    GetRowsFromDataFrame,\n",
    "    GetColumnFromDataFrame,\n",
    "    ApplyFunctionToSeriesNew,\n",
    ")\n",
    "from pyiron_nodes.math import Subtract, PseudoInverse, Sum, DotProduct\n",
    "\n",
    "file_path_0: str = \"ASSYST/Al_LDA.pckl.gz\"\n",
    "file_path_1: str = \"ASSYST/Al_PBE.pckl.gz\"\n",
    "r_min: float = 2.5\n",
    "r_max: float = 7\n",
    "num_points: int = 51\n",
    "max_row_index: int = -1\n",
    "store = False\n",
    "\n",
    "\n",
    "wf = Workflow(\"assyst_linear_fit3\")\n",
    "\n",
    "wf.ReadData = ReadPickledDatasetAsDataframe(\n",
    "    file_path=file_path_0,\n",
    "    compression=\"gzip\",\n",
    ")\n",
    "\n",
    "wf.ReadRefData = ReadPickledDatasetAsDataframe(\n",
    "    file_path=file_path_1,\n",
    "    compression=\"gzip\",\n",
    ")\n",
    "\n",
    "wf.Linspace = Linspace(x_min=r_min, x_max=r_max, num_points=num_points)\n",
    "\n",
    "wf.MergeDataFrames = MergeDataFrames(\n",
    "    df1=wf.ReadData,\n",
    "    df2=wf.ReadRefData,\n",
    "    on=\"name\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "wf.LinearInterpolationDescriptor = LinearInterpolationDescriptor(r_bins=wf.Linspace)\n",
    "\n",
    "wf.GetRowsFromDataFrame = GetRowsFromDataFrame(\n",
    "    df=wf.MergeDataFrames, max_index=max_row_index\n",
    ")\n",
    "\n",
    "wf.GetStructures = GetColumnFromDataFrame(\n",
    "    df=wf.GetRowsFromDataFrame, column_name=\"ase_atoms_x\"\n",
    ")\n",
    "\n",
    "wf.NumberOfAtoms = GetColumnFromDataFrame(\n",
    "    df=wf.GetRowsFromDataFrame, column_name=\"NUMBER_OF_ATOMS_x\"\n",
    ")\n",
    "\n",
    "wf.GetEnergy = GetColumnFromDataFrame(\n",
    "    df=wf.GetRowsFromDataFrame, column_name=\"energy_corrected_y\"\n",
    ")\n",
    "\n",
    "wf.GetRefEnergy = GetColumnFromDataFrame(\n",
    "    df=wf.GetRowsFromDataFrame, column_name=\"energy_corrected_x\"\n",
    ")\n",
    "\n",
    "wf.DesignMatrix = ApplyFunctionToSeriesNew(\n",
    "    series=wf.GetStructures,\n",
    "    function=wf.LinearInterpolationDescriptor,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "wf.DiffEnergy = Subtract(x=wf.GetEnergy, y=wf.GetRefEnergy)\n",
    "\n",
    "wf.PseudoInverse = PseudoInverse(matrix=wf.DesignMatrix)\n",
    "\n",
    "wf.Sum = Sum(x=wf.DesignMatrix, axis=0)\n",
    "\n",
    "wf.Coeff = DotProduct(a=wf.PseudoInverse, b=wf.DiffEnergy, store=store)\n",
    "wf.DiffEnergyPerAtom = Divide(wf.DiffEnergy, wf.NumberOfAtoms)\n",
    "wf.FitEnergyDiff = DotProduct(a=wf.DesignMatrix, b=wf.Coeff)\n",
    "wf.FitEnergyDiffPerAtom = Divide(wf.FitEnergyDiff, wf.NumberOfAtoms)\n",
    "\n",
    "wf.MergeDataFrames.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da056782-1d66-4349-8de6-676732524583",
   "metadata": {},
   "outputs": [],
   "source": [
    "@as_macro_node([\"coefficients\", \"design_matrix\", \"r_bins\", \"diff_energy_per_atom\", \"fit_diff_energy_per_atom\", \"number_of_atoms\"])\n",
    "def FitDiffPotential(\n",
    "    file_path_0: str = \"ASSYST/Al_LDA.pckl.gz\",\n",
    "    file_path_1: str = \"ASSYST/Al_PBE.pckl.gz\",\n",
    "    r_min: float = 2.5,\n",
    "    r_max: float = 7,\n",
    "    num_points: int = 51,\n",
    "    max_row_index: int = -1,\n",
    "    store: bool = True,\n",
    "):\n",
    "\n",
    "    from pyiron_workflow import Workflow\n",
    "    from pyiron_nodes.atomistic.ml_potentials.fitting.linearfit import (\n",
    "        ReadPickledDatasetAsDataframe,\n",
    "    )\n",
    "    from pyiron_nodes.math import Linspace, Divide, DotProduct\n",
    "    from pyiron_nodes.atomistic.structure.calc import LinearInterpolationDescriptor\n",
    "    from pyiron_nodes.dataframe import (\n",
    "        MergeDataFrames,\n",
    "        GetRowsFromDataFrame,\n",
    "        GetColumnFromDataFrame,\n",
    "        ApplyFunctionToSeriesNew,\n",
    "    )\n",
    "    from pyiron_nodes.math import Subtract, PseudoInverse, Sum, DotProduct\n",
    "\n",
    "    wf = Workflow(\"assyst_linear_fit3\")\n",
    "\n",
    "    wf.ReadData = ReadPickledDatasetAsDataframe(\n",
    "        file_path=file_path_0,\n",
    "        compression=\"gzip\",\n",
    "    )\n",
    "\n",
    "    wf.ReadRefData = ReadPickledDatasetAsDataframe(\n",
    "        file_path=file_path_1,\n",
    "        compression=\"gzip\",\n",
    "    )\n",
    "\n",
    "    wf.Linspace = Linspace(x_min=r_min, x_max=r_max, num_points=num_points)\n",
    "\n",
    "    wf.MergeDataFrames = MergeDataFrames(\n",
    "        df1=wf.ReadData,\n",
    "        df2=wf.ReadRefData,\n",
    "        on=\"name\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    wf.LinearInterpolationDescriptor = LinearInterpolationDescriptor(r_bins=wf.Linspace)\n",
    "\n",
    "    wf.GetRowsFromDataFrame = GetRowsFromDataFrame(\n",
    "        df=wf.MergeDataFrames, max_index=max_row_index\n",
    "    )\n",
    "\n",
    "    wf.GetStructures = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=\"ase_atoms_x\"\n",
    "    )\n",
    "\n",
    "    wf.NumberOfAtoms = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=\"NUMBER_OF_ATOMS_x\"\n",
    "    )\n",
    "\n",
    "    wf.GetEnergy = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=\"energy_corrected_y\"\n",
    "    )\n",
    "\n",
    "    wf.GetRefEnergy = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=\"energy_corrected_x\"\n",
    "    )\n",
    "\n",
    "    wf.DesignMatrix = ApplyFunctionToSeriesNew(\n",
    "        series=wf.GetStructures,\n",
    "        function=wf.LinearInterpolationDescriptor,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    wf.DiffEnergy = Subtract(x=wf.GetEnergy, y=wf.GetRefEnergy)\n",
    "\n",
    "    wf.PseudoInverse = PseudoInverse(matrix=wf.DesignMatrix)\n",
    "\n",
    "    wf.Sum = Sum(x=wf.DesignMatrix, axis=0)\n",
    "\n",
    "    wf.Coeff = DotProduct(a=wf.PseudoInverse, b=wf.DiffEnergy, store=store)\n",
    "    wf.DiffEnergyPerAtom = Divide(wf.DiffEnergy, wf.NumberOfAtoms)\n",
    "    wf.FitEnergyDiff = DotProduct(a=wf.DesignMatrix, b=wf.Coeff)\n",
    "    wf.FitEnergyDiffPerAtom = Divide(wf.FitEnergyDiff, wf.NumberOfAtoms)\n",
    "\n",
    "    return wf.Coeff, wf.DesignMatrix, wf.Linspace, wf.DiffEnergyPerAtom, wf.FitEnergyDiffPerAtom, wf.NumberOfAtoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf27ef2-f0ab-440a-a997-4f76559948d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3a507-ac8f-4b10-9304-a0f3e4a4e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow(['assyst_data', 'neighbors1', 'assyst_linear_fit3', 'experiment', 'Workflow_4'], gui_layout=layout) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790f812-541a-4afa-a615-2039c95e9dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fc77e-12c6-4241-abba-f1240ef1a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from pyiron_workflow.graph.base import (Graph, graph_to_code, collapse_node, Nodes, Node, GraphEdge, \n",
    "get_code_from_graph, GraphNode, get_updated_graph, collapse_node, add_node, _remove_virtual_edges, _remove_edges_to_hidden_nodes, copy_graph)\n",
    "from pyiron_workflow.graph.graph_json import _save_graph, _load_graph\n",
    "from pyiron_workflow.graph.gui import GuiGraph, _mark_node_as_collapsed\n",
    "\n",
    "wf = Workflow('test')\n",
    "\n",
    "from pyiron_nodes.atomistic.structure.build import CubicBulkCell, Bulk\n",
    "from pyiron_nodes.atomistic.structure.transform import Repeat\n",
    "\n",
    "structure = CubicBulkCell(\"Al\")\n",
    "# structure = Bulk(\"Al\")\n",
    "\n",
    "graph = Graph(label=\"test\")\n",
    "graph += structure\n",
    "\n",
    "graph_c = collapse_node(graph, \"CubicBulkCell\")\n",
    "\n",
    "state = graph_c.__getstate__()  #[\"nodes\"][\"CubicBulkCell\"]\n",
    "del state[\"nodes\"][\"CubicBulkCell\"][\"graph\"]\n",
    "state[\"nodes\"][\"CubicBulkCell\"][\"node\"] = graph.nodes[\"CubicBulkCell\"][\"node\"].__getstate__()\n",
    "state[\"nodes\"][\"CubicBulkCell\"][\"node_type\"] = \"node\"\n",
    "state[\"edges\"][\"values\"] = []\n",
    "state\n",
    "\n",
    "nodes = Nodes().__setstate__(state[\"nodes\"])\n",
    "nodes\n",
    "#new_graph = Graph().__setstate__(state)\n",
    "\n",
    "\n",
    "\n",
    "#_save_graph(graph, overwrite=True)\n",
    "#_load_graph(\"test.json\")\n",
    "# print (get_code_from_graph(graph.nodes[\"CubicBulkCell\"].graph, sort_graph=True, use_node_default=False))\n",
    "# print(graph_to_code(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a068bd6-a380-4187-9265-574cb05321d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b67062-3623-4d6f-88e1-ac9ee872f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "structure = CubicBulkCell(\"Al\")\n",
    "repeat = Repeat()\n",
    "\n",
    "graph = Graph(label=\"test\")\n",
    "graph = add_node(graph, structure, label=\"CubicBulk\")\n",
    "graph = add_node(graph, repeat, label=\"repeat1\")\n",
    "graph += GraphEdge(source=\"CubicBulk\", target=\"repeat1\", sourceHandle=\"structure\", targetHandle=\"structure\")\n",
    "\n",
    "\n",
    "def compact_graph(graph: Graph):\n",
    "    graph = copy_graph(graph)\n",
    "    for k, node in graph.nodes.items():\n",
    "        # find macro nodes in the top level and collapse them\n",
    "        if (node.graph is not None) and (node.parent_id is None) and (node.import_path is not None):\n",
    "            print(\"collapse: \", k)\n",
    "            new_node = GraphNode(node=node.node, \n",
    "                                 id=node.id,\n",
    "                                 label=node.label, \n",
    "                                 expanded=False, \n",
    "                                 import_path=node.import_path, \n",
    "                                 node_type=node.node_type)\n",
    "            graph.nodes[k] = new_node\n",
    "            graph = collapse_node(graph, k)\n",
    "            \n",
    "    graph = get_updated_graph(graph)\n",
    "    return graph \n",
    "\n",
    "\n",
    "cg = compact_graph(graph)\n",
    "state = cg.__getstate__()\n",
    "# state[\"edges\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420554cb-f5af-420c-a0df-af2b51506f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncompact_graph_from_state(state):\n",
    "    graph = Graph(label=state[\"label\"])\n",
    "    for k, node_state in state[\"nodes\"].items():\n",
    "        if isinstance(node_state, dict):\n",
    "            # print(k, type(node_state))\n",
    "            graph_node = GraphNode().__setstate__(node_state)\n",
    "            if (graph_node.node is None) and (graph_node.import_path is not None):\n",
    "                node = Node().__setstate__(node_state[\"node\"])\n",
    "                graph = add_node(graph, node, label=node.label)\n",
    "                graph = _mark_node_as_collapsed(graph, node.label)\n",
    "            else:\n",
    "                graph +=graph_node\n",
    "\n",
    "    for edge_state in state[\"edges\"][\"values\"]:\n",
    "        print(edge_state)\n",
    "        graph += GraphEdge(**edge_state)\n",
    "\n",
    "    return graph\n",
    "\n",
    "new_graph = uncompact_graph_from_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a932411-2628-4a2f-a2cc-e9bb4ace5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow([new_graph]) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d19328-abd1-4e97-9771-3b926c998759",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef01f6-6d16-429a-aa0f-6a6732ad7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "GuiGraph(new_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a83b36-8f1b-4988-97b9-602a9fcc1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nodes().__setstate__(state[\"nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869abdf-e512-4e83-883b-c957079eb0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "GuiGraph(cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aedc4e6-7f44-4062-955b-50f5c56f68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(label=\"test\")\n",
    "\n",
    "state[\"nodes\"][\"CubicBulkCell\"][\"expanded\"] = False\n",
    "node = GraphNode().__setstate__(state[\"nodes\"][\"CubicBulkCell\"]) #[\"node\"])\n",
    "\n",
    "node = Node().__setstate__(state[\"nodes\"][\"CubicBulkCell\"][\"node\"])\n",
    "\n",
    "graph = add_node(graph, node, label=state[\"nodes\"][\"CubicBulkCell\"][\"label\"])\n",
    "node.expanded = False\n",
    "\n",
    "graph = collapse_node(graph, \"CubicBulkCell\")\n",
    "\n",
    "graph = get_updated_graph(graph)\n",
    "node = graph.nodes[\"CubicBulkCell\"]\n",
    "node.graph = None\n",
    "#node.node_type = \"node\"\n",
    "print(graph_to_code(graph))\n",
    "\n",
    "# _save_graph(graph, overwrite=True)\n",
    "# _load_graph(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464b0c8-e140-492d-bb4c-ce4e8534e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.__getstate__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58b095-8c42-409a-aac1-7fc288d1b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GuiGraph(get_updated_graph(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38750882-72cd-4665-bb39-fcb949e841d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow.graph.gui import GuiGraph\n",
    "\n",
    "GuiGraph(graph.nodes[\"CubicBulkCell\"].graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e9d52-6f6a-444b-9e8a-9f82022603bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"nodes\"][\"CubicBulkCell\"][\"node\"]\n",
    "Node().__setstate__(state[\"nodes\"][\"CubicBulkCell\"][\"node\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debda59f-b201-44ca-b2fe-503c6a51302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from pyiron_workflow.graph.base import Graph, graph_to_code, collapse_node, Nodes, Node\n",
    "from pyiron_workflow.graph.graph_json import _save_graph, _load_graph\n",
    "\n",
    "wf = Workflow('test')\n",
    "\n",
    "from pyiron_nodes.atomistic.structure.build import CubicBulkCell, Bulk\n",
    "\n",
    "#structure = CubicBulkCell(\"Al\")\n",
    "structure = Bulk(\"Al\")\n",
    "\n",
    "graph = Graph(label=\"test\")\n",
    "graph += structure\n",
    "\n",
    "state = graph.__getstate__() \n",
    "#del state[\"nodes\"][\"CubicBulkCell\"][\"graph\"]\n",
    "#state[\"nodes\"][\"CubicBulkCell\"][\"node\"] = graph.nodes[\"CubicBulkCell\"][\"node\"].__getstate__()\n",
    "#state[\"edges\"][\"values\"] = []\n",
    "#state\n",
    "\n",
    "nodes = Nodes().__setstate__(state[\"nodes\"])\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c694dd2-f052-4d24-b4ce-917be8fefc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow.graph.base import get_graph_from_wf\n",
    "from pyiron_workflow.graph.gui import GuiGraph\n",
    "from pyiron_workflow.graph.graph_json import _save_graph, _load_graph\n",
    "\n",
    "graph = get_graph_from_wf(wf, wf_outputs=[wf.structure], out_labels=[\"structure\"])\n",
    "\n",
    "# _save_graph(graph, overwrite=True)\n",
    "# _load_graph(\"test.json\")\n",
    "# GuiGraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1466be-8072-4725-a7e4-8b85a20f0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import as_macro_node\n",
    "\n",
    "@as_macro_node(\"figure\")\n",
    "def assyst_linear_fit3(\n",
    "    ReadPickledDatasetAsDataframe__file_path: str = \"ASSYST/Al_LDA.pckl.gz\",\n",
    "    ReadPickledDatasetAsDataframe__compression: str = \"gzip\",\n",
    "    ReadPickledDatasetAsDataframe_1__file_path: str = \"ASSYST/Al_PBE.pckl.gz\",\n",
    "    ReadPickledDatasetAsDataframe_1__compression: str = \"gzip\",\n",
    "    Linspace__x_min: float = 2.5,\n",
    "    Linspace__x_max: float = 7,\n",
    "    Linspace__num_points: int = 51,\n",
    "    MergeDataFrames__on: str = \"name\",\n",
    "    MergeDataFrames__how: str = \"inner\",\n",
    "    GetRowsFromDataFrame__max_index: int = -1,\n",
    "    GetColumnFromDataFrame_2__column_name: str = \"ase_atoms_x\",\n",
    "    GetColumnFromDataFrame_3__column_name: str = \"energy_corrected_y\",\n",
    "    GetColumnFromDataFrame_1__column_name: str = \"energy_corrected_x\",\n",
    "    ApplyFunctionToSeries_2__store: bool = True,\n",
    "    Sum__axis: int = 0,\n",
    "    DotProduct__store: bool = True,\n",
    "):\n",
    "\n",
    "    from pyiron_workflow import Workflow\n",
    "\n",
    "    wf = Workflow(\"assyst_linear_fit3\")\n",
    "\n",
    "    from pyiron_nodes.atomistic.ml_potentials.fitting.linearfit import (\n",
    "        ReadPickledDatasetAsDataframe,\n",
    "    )\n",
    "\n",
    "    wf.ReadPickledDatasetAsDataframe = ReadPickledDatasetAsDataframe(\n",
    "        file_path=ReadPickledDatasetAsDataframe__file_path,\n",
    "        compression=ReadPickledDatasetAsDataframe__compression,\n",
    "    )\n",
    "    from pyiron_nodes.atomistic.ml_potentials.fitting.linearfit import (\n",
    "        ReadPickledDatasetAsDataframe,\n",
    "    )\n",
    "\n",
    "    wf.ReadPickledDatasetAsDataframe_1 = ReadPickledDatasetAsDataframe(\n",
    "        file_path=ReadPickledDatasetAsDataframe_1__file_path,\n",
    "        compression=ReadPickledDatasetAsDataframe_1__compression,\n",
    "    )\n",
    "    from pyiron_nodes.math import Linspace\n",
    "\n",
    "    wf.Linspace = Linspace(\n",
    "        x_min=Linspace__x_min, x_max=Linspace__x_max, num_points=Linspace__num_points\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import MergeDataFrames\n",
    "\n",
    "    wf.MergeDataFrames = MergeDataFrames(\n",
    "        df1=wf.ReadPickledDatasetAsDataframe,\n",
    "        df2=wf.ReadPickledDatasetAsDataframe_1,\n",
    "        on=MergeDataFrames__on,\n",
    "        how=MergeDataFrames__how,\n",
    "    )\n",
    "    from pyiron_nodes.atomistic.structure.calc import LinearInterpolationDescriptor\n",
    "\n",
    "    \n",
    "    wf.LinearInterpolationDescriptor = LinearInterpolationDescriptor(r_bins=wf.Linspace)\n",
    "    from pyiron_nodes.dataframe import GetRowsFromDataFrame\n",
    "\n",
    "    wf.GetRowsFromDataFrame = GetRowsFromDataFrame(\n",
    "        df=wf.MergeDataFrames, max_index=GetRowsFromDataFrame__max_index\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import GetColumnFromDataFrame\n",
    "\n",
    "    wf.GetColumnFromDataFrame_2 = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=GetColumnFromDataFrame_2__column_name\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import GetColumnFromDataFrame\n",
    "\n",
    "    wf.GetColumnFromDataFrame_3 = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=GetColumnFromDataFrame_3__column_name\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import GetColumnFromDataFrame\n",
    "\n",
    "    wf.GetColumnFromDataFrame_1 = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=GetColumnFromDataFrame_1__column_name\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import ApplyFunctionToSeriesNew\n",
    "\n",
    "    wf.ApplyFunctionToSeries_2 = ApplyFunctionToSeriesNew(\n",
    "        series=wf.GetColumnFromDataFrame_2,\n",
    "        function=wf.LinearInterpolationDescriptor,\n",
    "        store=ApplyFunctionToSeries_2__store,\n",
    "    )\n",
    "    from pyiron_nodes.math import Subtract\n",
    "\n",
    "    wf.Subtract = Subtract(x=wf.GetColumnFromDataFrame_1, y=wf.GetColumnFromDataFrame_3)\n",
    "    from pyiron_nodes.math import PseudoInverse\n",
    "\n",
    "    wf.PseudoInverse = PseudoInverse(matrix=wf.ApplyFunctionToSeries_2)\n",
    "    from pyiron_nodes.math import Sum\n",
    "\n",
    "    wf.Sum = Sum(x=wf.ApplyFunctionToSeries_2, axis=Sum__axis)\n",
    "    from pyiron_nodes.math import DotProduct\n",
    "\n",
    "    wf.DotProduct = DotProduct(\n",
    "        a=wf.PseudoInverse, b=wf.Subtract, store=DotProduct__store\n",
    "    )\n",
    "\n",
    "\n",
    "    return wf.DotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad85a31-b42b-47a4-b94f-68b65858e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assyst_linear_fit3().pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0865ba-8cad-4967-85ad-ebf13ed3ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx\n",
    "\n",
    "import calphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87f5db-0357-481b-9409-78fd2a73181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_nodes as pn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyiron_nodes.dataframe import ApplyFunctionToSeriesNew\n",
    "from pyiron_workflow import Workflow\n",
    "\n",
    "wf = Workflow(\"test\")\n",
    "\n",
    "structure = pn.atomistic.structure.build.CubicBulkCell('Al').run()\n",
    "\n",
    "series = pd.Series([structure, structure]) \n",
    "\n",
    "\n",
    "wf.node = pn.atomistic.structure.calc.LinearInterpolationDescriptor()\n",
    "\n",
    "wf.Apply_Function = ApplyFunctionToSeriesNew(\n",
    "    series=series,\n",
    "    function=wf.node,\n",
    "    store=False,\n",
    ")\n",
    "\n",
    "wf.Apply_Function.pull()\n",
    "# wf.node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08742f7d-5dad-4b51-be2f-b9ebbeba2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(node.kwargs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db595e24-ac0f-45ae-bfd0-8e7f3f825f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.Series([1,2]).apply(np.sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97258130-544a-4e16-bc8f-a0667216243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41ae1e-bd30-4c1d-891d-907af7448a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from structuretoolkit import get_neighbors, \n",
    "\n",
    "get_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea87011-615d-4121-a4bc-ad3de362fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_min = 0\n",
    "x_max = 1\n",
    "steps = 11\n",
    "x, dx = np.linspace(x_min, x_max, steps, retstep=True)\n",
    "y = np.zeros(steps)\n",
    "\n",
    "x0 = 0.3001\n",
    "i_left = int((x0 - x_min) * steps) \n",
    "\n",
    "w = (x0 - x[i_left])/dx\n",
    "print (i_left, x, w)\n",
    "y[i_left] += 1-w\n",
    "y[i_left + 1] = w\n",
    "x[i_left], x[i_left+1]\n",
    "np.sum(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28bcdc-4401-4ddb-b5ef-8780c94d892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_nodes as pn\n",
    "\n",
    "pn.atomistic.structure.build.CubicBulkCell('Al').run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be12613-6cbf-4d2d-8ad7-c33826159f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pyiron_nodes as pn\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def gaussian_weighted_histogram(data, bins=50, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Compute a Gaussian-weighted histogram for a list of floats.\n",
    "\n",
    "    Parameters:\n",
    "        data (list or np.ndarray): Input data (list of floats).\n",
    "        bins (int): Number of bins for the histogram.\n",
    "        sigma (float): Standard deviation of the Gaussian kernel.\n",
    "\n",
    "    Returns:\n",
    "        bin_centers (np.ndarray): Centers of the histogram bins.\n",
    "        weighted_histogram (np.ndarray): Gaussian-weighted histogram values.\n",
    "    \"\"\"\n",
    "    # Create histogram bins\n",
    "    bin_edges = np.linspace(min(data), max(data), bins + 1)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Initialize the weighted histogram\n",
    "    weighted_histogram = np.zeros_like(bin_centers)\n",
    "\n",
    "    # Apply Gaussian weighting for each data point\n",
    "    for x in data:\n",
    "        weights = norm.pdf(bin_centers, loc=x, scale=sigma)\n",
    "        weighted_histogram += weights\n",
    "\n",
    "    return bin_centers, weighted_histogram\n",
    "\n",
    "\n",
    "bulk = pn.atomistic.structure.build.Bulk('Al', cubic=True)\n",
    "\n",
    "bulk.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13125bfe-cd2b-4265-b431-402379e6996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow(['assyst',  'linearfit2', 'landau2', 'svd_solver', 'linear_fit',  'plot_sin', 'supercell_conv']) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419a726-ca89-4c59-9ad6-47b02dbe59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d6011-2845-447b-99f2-183777aa5a80",
   "metadata": {},
   "source": [
    "ToDo (key priorities):\n",
    "- renaming of labels\n",
    "- grouping with renaming of group names\n",
    "- sorting and search in node tree\n",
    "- js gui input - sign fails (e.g. -1) gives json reading error (solved in gui.py)\n",
    "- run only needed nodes (where no hashed output is available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b42cbe-ad07-4f38-b717-46a700394379",
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bd764-13ac-4908-9a1e-d89334649201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "my_str = \"{\\\"label\\\":\\\"Identity\\\",\\\"handle\\\":0,\\\"value\\\":\\\"-1\\\"}\"\n",
    "\n",
    "json.loads(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96da94-9d72-40e5-a0bd-addf5541a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lst = []\n",
    "for i in [[0], [1,1]]:\n",
    "    lst += list(np.array(i))\n",
    "lst\n",
    "\n",
    "np.sqrt(0.000496688)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e83ebc-2f4c-4f27-886e-6726d71f6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.append()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ab9c4-30dd-4a9e-8153-92311bf0ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow, as_macro_node\n",
    "import pyiron_nodes as pn\n",
    "\n",
    "pn.atomistic.ml_potentials.fitting.linear_ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c79bbb-cf04-4c8b-9cbc-d58a1c277afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@as_macro_node(\"phase_data\")\n",
    "def ComputPhaseDiagram(filename: str=\"MgCaFreeEnergies.pckl.gz\", T_min:int=300, T_max:int=1100, T_steps=20):\n",
    "    wf = Workflow(\"PhaseDiagram\")\n",
    "    wf.read_data = pn.utilities.ReadDataFrame(filename=filename, compression=\"gzip\")\n",
    "    wf.phases_from_df = pn.atomistic.thermodynamics.landau.phases.PhasesFromDataFrame(dataframe=wf.read_data)\n",
    "    wf.temperatures = pn.math.Linspace(x_min=T_min, x_max=T_max, num_points=T_steps, endpoint=True)\n",
    "    wf.calc_phase_diagram = pn.atomistic.thermodynamics.landau.plot.CalcPhaseDiagram(phases=wf.phases_from_df.outputs.phase_list, temperatures=wf.temperatures, refine=True)\n",
    "    return wf.calc_phase_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab841b1-55de-4684-8634-791abeb12cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ComputPhaseDiagram().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7826373-d048-44b8-b2bb-048404dbe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyace import PyACECalculator\n",
    "import pyiron_nodes\n",
    "from pyiron_workflow import Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5fbcb-f42c-4987-a7e5-1d842ca7ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow('linearfit2')\n",
    "\n",
    "wf.ParameterizePotentialConfig = pyiron_nodes.atomistic.ml_potentials.fitting.linearfit.ParameterizePotentialConfig(number_of_functions_per_element=100) \n",
    "wf.ReadPickledDatasetAsDataframe = pyiron_nodes.atomistic.ml_potentials.fitting.linearfit.ReadPickledDatasetAsDataframe(file_path=\"mgca.pckl.tgz\") \n",
    "wf.SplitTrainingAndTesting = pyiron_nodes.atomistic.ml_potentials.fitting.linearfit.SplitTrainingAndTesting(data_df=wf.ReadPickledDatasetAsDataframe) \n",
    "wf.RunLinearFit = pyiron_nodes.atomistic.ml_potentials.fitting.linearfit.RunLinearFit(df_test=wf.SplitTrainingAndTesting.outputs.df_testing, \n",
    "                                                                                      df_train=wf.SplitTrainingAndTesting.outputs.df_training, potential_config=wf.ParameterizePotentialConfig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36130a29-c134-4a7f-a1e5-c1f6cfbf358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = wf.RunLinearFit.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aee5d3-38fd-46bb-acd8-4684321ef2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ace = PyACECalculator(fit)\n",
    "ace.basis.basis_coeffs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc94f0-d1c4-4842-a4e2-0889a141229f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0d690-7102-4006-aa26-781033b7e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.atomistic.structure.build import Bulk\n",
    "\n",
    "structure = Bulk(\"Ca\", cubic=True).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b220643-4cba-4507-a407-3127a8c3dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ace.calculate(atoms=structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac14c8-9893-4147-8cb8-555c4aaff09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd81338-b341-427b-8716-c79b682a69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = wf.SplitTrainingAndTesting.outputs.df_testing.value\n",
    "potential_config = wf.ParameterizePotentialConfig.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ceab9-4ce4-4e16-aa7b-f2348d269978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyace.linearacefit import LinearACEFit, LinearACEDataset\n",
    "from pyace import create_multispecies_basis_config\n",
    "\n",
    "from pyiron_snippets.logger import logger\n",
    "\n",
    "logger.setLevel(30)\n",
    "verbose = False\n",
    "\n",
    "elements_set = set()\n",
    "for at in df_train[\"ase_atoms\"]:\n",
    "    elements_set.update(at.get_chemical_symbols())\n",
    "\n",
    "elements = sorted(elements_set)\n",
    "potential_config.elements = elements\n",
    "potential_config_dict = potential_config.to_dict()\n",
    "\n",
    "bconf = create_multispecies_basis_config(potential_config_dict)\n",
    "\n",
    "train_ds = LinearACEDataset(bconf, df_train)\n",
    "train_ds.construct_design_matrix(verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979b069-28c5-42b7-bd13-75254cf7840a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d3e51-5bc9-41a5-a929-bb4f7741604e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ef8eb-734b-4fae-96dd-5d04c976308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = train_ds.design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d126b71-4ce6-4f0c-82bd-bb17bc51d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab\n",
    "\n",
    "# np.linalg.svd(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da8230-5c5e-4558-892c-d2efc9bc30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "u, s, vh = np.linalg.svd(mat, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061ddd7-46a5-4793-b6d3-31b602bc609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vh[96]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cfe938-b15f-4770-98b0-e5a90a8bed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_mat = np.zeros(mat.shape)\n",
    "norm_list = []\n",
    "for i in range(len(s)):\n",
    "    svd_mat += np.outer(u.T[i], vh[i]) * s[i]\n",
    "    norm_list.append(np.linalg.norm(svd_mat - mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71954f20-5b70-4155-bd9c-eabe2850f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(norm_list, label='norm')\n",
    "plt.plot(s, label='s')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31946bf-bbdd-4467-9329-13b5fae85daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.energy_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac80fe1f-2b1c-4cc8-89b0-d5c349006c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference data\n",
    "training_number_of_atoms = df_train.NUMBER_OF_ATOMS.to_numpy()\n",
    "training_energies = df_train.energy_corrected.to_numpy()\n",
    "\n",
    "np.sum(training_number_of_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243372bd-8f8c-4e83-929f-b38e4d9990d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148b5d0-32a2-443b-a4dd-d3448a291524",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.construct_target_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d85c3b-dc13-4eaa-84ac-32bb2cab41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds.get_energies_per_atom())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949fe45-fe1b-4f95-89ca-18d1acc5bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.get_energies_per_atom??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95239e58-2e50-43aa-ac21-418f764483c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.get_target_vector??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3233e-6257-4928-bc1c-b03fa8410217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
