{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a3828e-2e58-495c-8577-42137d640fc6",
   "metadata": {},
   "source": [
    "# Demo for automated computation of binary phase diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c16662a-ddf2-4329-85d5-7ae8419933ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyiron_workflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyiron_workflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gui, base\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyiron_workflow'"
     ]
    }
   ],
   "source": [
    "from pyiron_workflow.graph import gui, base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9288759-db5b-42c9-a4bf-7b02d33455b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow([\"water\"]) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70bf4b-2872-4b57-abbd-e4ae0ce76ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = pr.create.job.Lammps('water_equilibration', delete_existing_job = True)\n",
    "\n",
    "solvated_electrode.add_tag(selective_dynamics=[True, True, True])\n",
    "solvated_electrode.selective_dynamics[solvated_electrode.select_index(\"Al\")] = [False, False, False]\n",
    "\n",
    "epsilon = 0.102\n",
    "sigma = 3.188\n",
    "water_potential = pandas.DataFrame({\n",
    "    'Name': ['H2O_tip3p'],\n",
    "    'Filename': [[]],\n",
    "    'Model': [\"TIP3P\"],\n",
    "    'Species': [['H','O','Al']],\n",
    "    'Config': [[\n",
    "    '# @potential_species H_O  ### species in potential\\n',\n",
    "     '# W.L. Jorgensen',\n",
    "     'The Journal of Chemical Physics 79',\n",
    "     '926 (1983); https://doi.org/10.1063/1.445869 \\n',\n",
    "     '#\\n',\n",
    "     '\\n',\n",
    "     'units      real\\n',\n",
    "     'dimension  3\\n',\n",
    "     'atom_style full\\n',\n",
    "     '\\n',\n",
    "     '# create groups ###\\n',\n",
    "     'group O type 2\\n',\n",
    "     'group H type 1\\n',\n",
    "     'group Al type 3\\n',\n",
    "     '\\n',\n",
    "     '## set charges - beside manually ###\\n',\n",
    "     'set group O charge -0.830\\n',\n",
    "     'set group H charge 0.415\\n',\n",
    "     'set group Al charge 0.2\\n',           \n",
    "     '\\n',\n",
    "     '### TIP3P Potential Parameters ###\\n',\n",
    "     'pair_style lj/cut/coul/long 10.0\\n',\n",
    "     'pair_coeff * * 0.000 0.000 \\n',\n",
    "     'pair_coeff 2 2 0.102 3.188 \\n',\n",
    "     'pair_coeff 2 3 {:.4} {:.4} \\n'.format(epsilon, sigma),      \n",
    "     'bond_style  harmonic\\n',\n",
    "     'bond_coeff  1 450 0.9572\\n',\n",
    "     'angle_style harmonic\\n',\n",
    "     'angle_coeff 1 55 104.52\\n',\n",
    "     'kspace_style pppm 1.0e-5   # final npt relaxation\\n',\n",
    "     '\\n']]})\n",
    "\n",
    "j.structure = solvated_electrode\n",
    "j.potential = water_potential\n",
    "j.calc_md(temperature=300)   \n",
    "\n",
    "j.run(run_mode='queue', delete_existing_job=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28622ae8-25a6-427c-8db6-cdcbe3b109cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056dfa54-bb3c-4814-a3d9-f48307315802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_database.instance_database as idb\n",
    "from pyiron_nodes.math import Sin\n",
    "\n",
    "sin = Sin(3)\n",
    "\n",
    "idb.store_node_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8c3db-a958-44d2-8826-795ba68ab8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow([\"phonopy\", \"show_code\", \"phonopy_macro\", \"phonopy_free_energy\", \"elastic\", \"elastic_macro\", \"elastic_macro\"]) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577afd28-8ab6-4084-9395-567485fe4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow([\"phonopy\", \"show_code\", \"phonopy_macro\", \"phonopy_free_energy\", \"elastic\", \"elastic_macro\", \"elastic_macro2\"]) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6366f-8acc-4516-8426-8509d1d36ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.atomistic.property.elastic import ComputeElasticConstants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3b91e-c367-4c43-84b2-8e7eac71183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow, Node\n",
    "import pyiron_nodes as pn\n",
    "\n",
    "wf = Workflow(\"test\")\n",
    "wf.node = Node()\n",
    "wf.sin = pn.math.Sin(x=3)\n",
    "\n",
    "wf.run(), wf.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed21f34-7708-4045-a334-032f0bb56c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import as_macro_node, as_function_node, Node\n",
    "from pyiron_nodes.atomistic.structure.build import Bulk\n",
    "from pyiron_nodes.atomistic.engine.ase import M3GNet\n",
    "from pyiron_nodes.atomistic.calculator.ase import StaticEnergy, Static\n",
    "from pyiron_nodes.atomistic.property.elastic import InputElasticTensor, SymmetryAnalysis, GenerateStructures, AnalyseStructures\n",
    "\n",
    "@as_function_node\n",
    "def ComputeElasticConstants(\n",
    "    structure,\n",
    "    engine,\n",
    "    # calculator: Node = None,    \n",
    "    input_elastic_tensor: InputElasticTensor = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the elastic constants of a structure using an ASE calculator.\n",
    "    \"\"\"\n",
    "    from pyiron_workflow import Workflow\n",
    "    from pyiron_nodes.controls import iterate, IterToDataFrame, Print\n",
    "    from pyiron_nodes.atomistic.calculator.ase import StaticEnergy, Static\n",
    "    from pyiron_nodes.atomistic.property.phonons import GetFreeEnergy\n",
    "\n",
    "    wf = Workflow(\"elastic_constants\")\n",
    "    if input_elastic_tensor is None:\n",
    "        input_elastic_tensor = InputElasticTensor()\n",
    "    # wf.print = Print(f\"calculator: {calculator}\")\n",
    "    # wf.calculator = StaticEnergy(structure=structure, engine=engine)\n",
    "    wf.calculator = GetFreeEnergy(structure=structure, engine=engine)\n",
    "    print(f\"Using calculator: {wf.calculator}\")\n",
    "    # print(f\"Input calculator: {calculator}\")\n",
    "    wf.symmetry = SymmetryAnalysis(structure=structure, parameters=input_elastic_tensor)\n",
    "    wf.structures = GenerateStructures(\n",
    "        structure=structure, analysis=wf.symmetry, parameters=input_elastic_tensor\n",
    "    )\n",
    "    wf.energies = iterate(\n",
    "        node=wf.calculator,\n",
    "        values=wf.structures.outputs.structures,\n",
    "        input_label=\"structure\",\n",
    "    )\n",
    "\n",
    "    wf.elastic_constants = AnalyseStructures(\n",
    "        energies=wf.energies,\n",
    "        job_names=wf.structures.outputs.job_names,\n",
    "        analysis=wf.symmetry,\n",
    "        parameters=input_elastic_tensor,\n",
    "    )\n",
    "    elastic_constants = wf.energies.pull()\n",
    "    return elastic_constants\n",
    "\n",
    "bulk = Bulk(\"Al\", cubic=True).run()\n",
    "engine = M3GNet().run()\n",
    "calculator = StaticEnergy(bulk, engine=engine) #.run()\n",
    "ComputeElasticConstants(bulk, engine, calculator).run()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af252edd-3dec-4ce9-ab4e-09bfe5432481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from pyiron_nodes.controls import iterate, IterToDataFrame, Print\n",
    "from pyiron_nodes.atomistic.calculator.ase import StaticEnergy, Static\n",
    "from pyiron_nodes.atomistic.property.phonons import GetFreeEnergy\n",
    "\n",
    "from pyiron_workflow import as_macro_node, as_function_node, Node\n",
    "from pyiron_nodes.atomistic.structure.build import Bulk\n",
    "from pyiron_nodes.atomistic.engine.ase import M3GNet\n",
    "from pyiron_nodes.atomistic.calculator.ase import StaticEnergy, Static\n",
    "from pyiron_nodes.atomistic.property.elastic import InputElasticTensor, SymmetryAnalysis, GenerateStructures, AnalyseStructures\n",
    "\n",
    "structure = Bulk(\"Al\", cubic=True).run()\n",
    "engine = M3GNet().run()\n",
    "calculator = StaticEnergy(structure, engine=engine)\n",
    "calculator = GetFreeEnergy(structure=structure, engine=engine)\n",
    "parameters = InputElasticTensor(num_of_point=6)\n",
    "\n",
    "@as_function_node\n",
    "def elastic_constants(structure, calculator: Node, input_elastic_tensor:InputElasticTensor=None):\n",
    "    wf = Workflow(\"elastic_constants\")\n",
    "    if input_elastic_tensor is None:\n",
    "        input_elastic_tensor = InputElasticTensor().run()\n",
    "    wf.calculator = calculator \n",
    "    \n",
    "    wf.symmetry = SymmetryAnalysis(structure=structure, parameters=input_elastic_tensor)\n",
    "    wf.structures = GenerateStructures(\n",
    "        structure=structure, analysis=wf.symmetry, parameters=input_elastic_tensor\n",
    "    )\n",
    "    wf.energies = iterate(\n",
    "        node=wf.calculator,\n",
    "        values=wf.structures.outputs.structures,\n",
    "        input_label=\"structure\",\n",
    "    )\n",
    "    \n",
    "    wf.elastic_constants = AnalyseStructures(\n",
    "        energies=wf.energies,\n",
    "        job_names=wf.structures.outputs.job_names,\n",
    "        analysis=wf.symmetry,\n",
    "        parameters=input_elastic_tensor,\n",
    "    )\n",
    "    \n",
    "    elastic_constants = wf.elastic_constants.pull()\n",
    "    return elastic_constants\n",
    "\n",
    "print(calculator)\n",
    "node = elastic_constants(structure, calculator, parameters)\n",
    "node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9fe1e-32cc-479d-9886-0a71260229ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phonopy import Phonopy\n",
    "from structuretoolkit.common import atoms_to_phonopy, phonopy_to_atoms\n",
    "\n",
    "from pyiron_nodes.atomistic.structure.build import CubicBulkCell\n",
    "\n",
    "Al = CubicBulkCell('Al', 3).run()\n",
    "phonopy = Phonopy(unitcell=atoms_to_phonopy(Al))\n",
    "phonopy.generate_displacements(distance=0.01, is_plusminus='auto', is_diagonal=True, is_trigonal=False, number_of_snapshots=None, random_seed=None, temperature=None, cutoff_frequency=None, max_distance=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a038a1b-20cc-4aa7-9be5-233779c6e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.atomistic.property.phonons import ThermalProperties\n",
    "\n",
    "ThermalProperties().dataclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cd898-2884-4d5a-8e1a-f454194504eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import as_out_dataclass_node\n",
    "import numpy as np\n",
    "\n",
    "@as_out_dataclass_node\n",
    "class ThermalProperties:\n",
    "    from dataclasses import field\n",
    "\n",
    "    temperatures: list | np.ndarray = field(\n",
    "        default_factory=lambda: np.array([])\n",
    "    )\n",
    "\n",
    "ThermalProperties().dataclass(temperatures=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86dc29e-f83f-4b06-9897-8e5ae2e9c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.atomistic.property.phonons import PhonopyParameters\n",
    "from dataclasses import asdict\n",
    "\n",
    "pp = PhonopyParameters().run()\n",
    "asdict(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b9e7a-4a13-49ce-a433-8db90731665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow(['assyst',  'linearfit2', 'landau2']) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44320e3-e06c-478c-99b0-d2df07ec2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = gui.GUILayout()\n",
    "layout.flow_widget_height = 800\n",
    "\n",
    "# working: 'Workflow_4', 'experiment', 'assyst_linear_fit3', 'neighbors1', 'energy', 'murn4', 'db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd419c8-b698-45f7-9a1b-17ffc4a3d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow(['Workflow_4', 'assyst_linear_fit3', 'macro_fit', 'bspline_test', 'bspline_test3', 'iter_test', 'descriptor'], gui_layout=layout) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9dcc2-1b25-4391-901b-fac551832eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011a987-a4ec-4f5f-b713-cdef36c2eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_nodes as pn\n",
    "\n",
    "Al = pn.atomistic.structure.build.Bulk('Al')\n",
    "Al.inputs.name.value = \"Cu\"\n",
    "Al.inputs[\"name\"].value =\"Fe\"\n",
    "Al.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4db80d-47d3-4413-8c65-6b0e73bbdaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Tuple, List, Dict, Any\n",
    "from pyiron_workflow import Node\n",
    "from pyiron_workflow.simple_workflow import Data, Port, PORT_LABEL, PORT_DEFAULT, PORT_TYPE, PORT_VALUE\n",
    "\n",
    "\n",
    "### BEGIN: Helper function from previous answer with stricter checks\n",
    "class ReturnAnalysisError(Exception):\n",
    "    pass\n",
    "\n",
    "def analyze_function_code(func_str):\n",
    "    tree = ast.parse(func_str)\n",
    "    # Find the first function definition\n",
    "    func_node = next(node for node in tree.body if isinstance(node, ast.FunctionDef))\n",
    "    # Arguments\n",
    "    args_info = []\n",
    "    all_args = func_node.args.args\n",
    "    defaults = [None] * (len(all_args) - len(func_node.args.defaults)) + func_node.args.defaults\n",
    "    for arg, default in zip(all_args, defaults):\n",
    "        arg_name = arg.arg\n",
    "        arg_type = ast.unparse(arg.annotation) if arg.annotation else None\n",
    "        if default is not None:\n",
    "            try:\n",
    "                default_value = ast.literal_eval(default)\n",
    "            except Exception:\n",
    "                default_value = ast.unparse(default)\n",
    "        else:\n",
    "            default_value = None\n",
    "        args_info.append({\n",
    "            'name': arg_name,\n",
    "            'type': arg_type,\n",
    "            'default': default_value\n",
    "        })\n",
    "    # Return type annotation\n",
    "    return_type = ast.unparse(func_node.returns) if func_node.returns else None\n",
    "\n",
    "    # Extract return variable names from 'return' (with safety checks)\n",
    "    class ReturnVisitor(ast.NodeVisitor):\n",
    "        def __init__(self):\n",
    "            self.return_vars = []\n",
    "        def visit_Return(self, node):\n",
    "            if node.value is None:\n",
    "                self.return_vars.append(None)\n",
    "            elif isinstance(node.value, ast.Name):\n",
    "                self.return_vars.append(node.value.id)\n",
    "            elif isinstance(node.value, ast.Tuple):\n",
    "                names = []\n",
    "                for elt in node.value.elts:\n",
    "                    if isinstance(elt, ast.Name):\n",
    "                        names.append(elt.id)\n",
    "                    else:\n",
    "                        raise ReturnAnalysisError(\n",
    "                            f\"Invalid return variable: {ast.unparse(elt)}. Must return variable names, not expressions.\"\n",
    "                        )\n",
    "                self.return_vars.append(tuple(names))\n",
    "            else:\n",
    "                raise ReturnAnalysisError(\n",
    "                    f\"Invalid return value: {ast.unparse(node.value)}. Must return variable names, not expressions.\"\n",
    "                )\n",
    "    visitor = ReturnVisitor()\n",
    "    visitor.visit(func_node)\n",
    "    if len(visitor.return_vars) > 1:\n",
    "        raise ReturnAnalysisError(\"Function contains multiple 'return' statements, which is not supported.\")\n",
    "    return_vars = visitor.return_vars[0] if visitor.return_vars else None\n",
    "    return {\n",
    "        'function_name': func_node.name,\n",
    "        'arguments': args_info,\n",
    "        'return_type': return_type,\n",
    "        'returned_variables': return_vars\n",
    "    }\n",
    "### END: Helper function\n",
    "\n",
    "### The requested main function:\n",
    "def function_string_to_node(func_str):\n",
    "    # Analyze the function code to extract port specifications and return variable names\n",
    "    info = analyze_function_code(func_str)\n",
    "    arg_info = info['arguments']\n",
    "    return_type = info['return_type']\n",
    "    return_vars = info['returned_variables']\n",
    "    # Compose code string and function object\n",
    "    local_vars = {}\n",
    "    exec_globals = {\n",
    "        '__builtins__': __builtins__,\n",
    "        'Tuple': Tuple,\n",
    "        'List': List,\n",
    "        'Dict': Dict,\n",
    "        'Any': Any,\n",
    "    }\n",
    "    exec(func_str, exec_globals, local_vars)\n",
    "    fn = [v for k,v in local_vars.items() if callable(v)][0]  # Gets the defined function\n",
    "    \n",
    "    # Prepare inputs for Node\n",
    "    inputs = Data({\n",
    "        PORT_LABEL: [arg['name'] for arg in arg_info],\n",
    "        PORT_TYPE: [arg['type'] for arg in arg_info],\n",
    "        PORT_DEFAULT: [arg['default'] for arg in arg_info],\n",
    "        PORT_VALUE: [None] * len(arg_info),\n",
    "        \"ready\": [False] * len(arg_info)\n",
    "    }, attribute=Port)\n",
    "\n",
    "    # Prepare outputs for Node\n",
    "    if return_vars is None:\n",
    "        output_labels = []\n",
    "        output_types = []\n",
    "    elif isinstance(return_vars, str):\n",
    "        output_labels = [return_vars]\n",
    "        output_types = [return_type]\n",
    "    else:  # tuple of names\n",
    "        output_labels = list(return_vars)\n",
    "        # split return_type if it's a tuple type (e.g. Tuple[int,int])\n",
    "        # Otherwise just assign the same return_type to all outputs for lack of better info\n",
    "        if return_type and return_type.startswith('Tuple['):\n",
    "            inside = return_type[6:-1]\n",
    "            out_types = [s.strip() for s in inside.split(',')]\n",
    "            if len(out_types) == len(output_labels):\n",
    "                output_types = out_types\n",
    "            else:\n",
    "                output_types = [return_type] * len(output_labels)\n",
    "        else:\n",
    "            output_types = [return_type] * len(output_labels)\n",
    "    outputs = Data({\n",
    "        PORT_LABEL: output_labels,\n",
    "        PORT_TYPE: output_types,\n",
    "        PORT_VALUE: [None]*len(output_labels),\n",
    "        \"ready\": [False] * len(output_labels)\n",
    "    }, attribute=Port)\n",
    "    \n",
    "    node = Node(\n",
    "        func=fn,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        label=info['function_name'],\n",
    "        output_labels=output_labels if output_labels else None,\n",
    "        node_type=\"function_node\"\n",
    "    )\n",
    "    return node\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f902ff-97e7-42b4-8cb4-307d3ee6ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with an example\n",
    "\n",
    "func_str = '''\n",
    "def AddMultiply(x: float, y: int = 2) -> Tuple[float, float]:\n",
    "    z = x + y\n",
    "    w = x * y\n",
    "    return z, w\n",
    "'''\n",
    "n = function_string_to_node(func_str)\n",
    "n(x=3, y=2)\n",
    "n.outputs.z.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3112599-b72f-4eb3-8e66-0830d3969932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "PORT_LABEL = 'label'\n",
    "PORT_TYPE = 'type'\n",
    "PORT_DEFAULT = 'default'\n",
    "PORT_VALUE = 'value'\n",
    "\n",
    "class Port:\n",
    "    \"\"\"Holds the attributes of a single port.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        label: str,\n",
    "        type_: Optional[Any] = None,\n",
    "        default: Optional[Any] = None,\n",
    "        value: Optional[Any] = None\n",
    "    ) -> None:\n",
    "        self.label = label\n",
    "        self.type = type_\n",
    "        self.default = default\n",
    "        self.value = value\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f\"Port(label={self.label!r}, type={self.type!r}, \"\n",
    "                f\"default={self.default!r}, value={self.value!r})\")\n",
    "\n",
    "\n",
    "class Data:\n",
    "    \"\"\"Holds a set of Port objects, mapped by their label (as attributes).\"\"\"\n",
    "    def __init__(self, port_dict: Dict[str, List[Any]]) -> None:\n",
    "        # Determine number of ports:\n",
    "        primary_key = PORT_LABEL\n",
    "        labels = port_dict.get(primary_key, [])\n",
    "        # get the keys in port_dict that will be attributes of Port:\n",
    "        keys = list(port_dict.keys())\n",
    "        for i, label in enumerate(labels):\n",
    "            attrs = {}\n",
    "            for key in keys:\n",
    "                value_list = port_dict.get(key, [])\n",
    "                attrs[key] = value_list[i] if i < len(value_list) else None\n",
    "            # Create Port instance with unpacked dict and add it as attribute\n",
    "            self.__setattr__(label, Port(\n",
    "                label=attrs.get(PORT_LABEL),\n",
    "                type_=attrs.get(PORT_TYPE),\n",
    "                default=attrs.get(PORT_DEFAULT),\n",
    "                value=attrs.get(PORT_VALUE)\n",
    "            ))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        ports = [attr for attr in self.__dict__ if isinstance(getattr(self, attr), Port)]\n",
    "        return f\"Data({', '.join(ports)})\"\n",
    "\n",
    "\n",
    "# --- Example usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    input = Data({\n",
    "        PORT_LABEL: ['label_1', 'label_2'],\n",
    "        PORT_TYPE: ['int', 'float'],\n",
    "        PORT_DEFAULT: [0, 1.0],\n",
    "        PORT_VALUE: [None, None],\n",
    "    })\n",
    "    port_1 = input.label_1\n",
    "    print(port_1)              # Port(label='label_1', type='int', default=0, value=None)\n",
    "    print(port_1.label)        # 'label_1'\n",
    "    print(port_1.type)         # 'int'\n",
    "    print(port_1.default)      # 0\n",
    "    print(port_1.value)        # None\n",
    "\n",
    "    port_2 = input.label_2\n",
    "    print(port_2)              # Port(label='label_2', type='float', default=1.0, value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994930ff-cda5-4267-b49e-11997117e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import as_function_node, Workflow\n",
    "from pyiron_workflow.simple_workflow import _return_as_function_node\n",
    "\n",
    "\n",
    "@as_function_node\n",
    "def CodeToNode(code):\n",
    "    node = function_string_to_node(code)\n",
    "    return code\n",
    "\n",
    "\n",
    "wf = Workflow('CodeEditor')\n",
    "wf.add_multiply = CodeToNode(code=func_str)   \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5683f-b5cd-4ed7-acba-b77ebbd279d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin(x: float):\n",
    "    import numpy as np\n",
    "    sin = np.sin(x)\n",
    "    return sin\n",
    "\n",
    "_return_as_function_node(sin,'Sin', ['sin'], 'function_node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e39aa-963b-4426-981c-d6c534f7a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca76eb79-bff2-4936-bd7a-dc55fdaf5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "from scipy.interpolate import BSpline\n",
    "\n",
    "BSpline.design_matrix??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de52c2-91dd-4b8f-8ca2-578d51f3e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.atomistic.structure.calc import FitDiffPotential2\n",
    "\n",
    "FitDiffPotential2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41210da7-aafa-43cd-9ba3-97d17e62bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from pyiron_nodes.atomistic.ml_potentials.fitting.linearfit import (\n",
    "    ReadPickledDatasetAsDataframe,\n",
    ")\n",
    "from pyiron_nodes.math import Linspace, Divide, DotProduct\n",
    "from pyiron_nodes.atomistic.structure.calc import LinearInterpolationDescriptor\n",
    "from pyiron_nodes.dataframe import (\n",
    "    MergeDataFrames,\n",
    "    GetRowsFromDataFrame,\n",
    "    GetColumnFromDataFrame,\n",
    "    ApplyFunctionToSeriesNew,\n",
    ")\n",
    "from pyiron_nodes.math import Subtract, PseudoInverse, Sum, DotProduct\n",
    "\n",
    "file_path_0: str = \"ASSYST/Al_LDA.pckl.gz\"\n",
    "file_path_1: str = \"ASSYST/Al_PBE.pckl.gz\"\n",
    "r_min: float = 2.5\n",
    "r_max: float = 7\n",
    "num_points: int = 51\n",
    "max_row_index: int = -1\n",
    "store = False\n",
    "\n",
    "\n",
    "wf = Workflow(\"assyst_linear_fit3\")\n",
    "\n",
    "wf.ReadData = ReadPickledDatasetAsDataframe(\n",
    "    file_path=file_path_0,\n",
    "    compression=\"gzip\",\n",
    ")\n",
    "\n",
    "wf.ReadRefData = ReadPickledDatasetAsDataframe(\n",
    "    file_path=file_path_1,\n",
    "    compression=\"gzip\",\n",
    ")\n",
    "\n",
    "wf.Linspace = Linspace(x_min=r_min, x_max=r_max, num_points=num_points)\n",
    "\n",
    "wf.MergeDataFrames = MergeDataFrames(\n",
    "    df1=wf.ReadData,\n",
    "    df2=wf.ReadRefData,\n",
    "    on=\"name\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "wf.LinearInterpolationDescriptor = LinearInterpolationDescriptor(r_bins=wf.Linspace)\n",
    "\n",
    "wf.GetRowsFromDataFrame = GetRowsFromDataFrame(\n",
    "    df=wf.MergeDataFrames, max_index=max_row_index\n",
    ")\n",
    "\n",
    "wf.GetStructures = GetColumnFromDataFrame(\n",
    "    df=wf.GetRowsFromDataFrame, column_name=\"ase_atoms_x\"\n",
    ")\n",
    "\n",
    "wf.NumberOfAtoms = GetColumnFromDataFrame(\n",
    "    df=wf.GetRowsFromDataFrame, column_name=\"NUMBER_OF_ATOMS_x\"\n",
    ")\n",
    "\n",
    "wf.GetEnergy = GetColumnFromDataFrame(\n",
    "    df=wf.GetRowsFromDataFrame, column_name=\"energy_corrected_y\"\n",
    ")\n",
    "\n",
    "wf.GetRefEnergy = GetColumnFromDataFrame(\n",
    "    df=wf.GetRowsFromDataFrame, column_name=\"energy_corrected_x\"\n",
    ")\n",
    "\n",
    "wf.DesignMatrix = ApplyFunctionToSeriesNew(\n",
    "    series=wf.GetStructures,\n",
    "    function=wf.LinearInterpolationDescriptor,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "wf.DiffEnergy = Subtract(x=wf.GetEnergy, y=wf.GetRefEnergy)\n",
    "\n",
    "wf.PseudoInverse = PseudoInverse(matrix=wf.DesignMatrix)\n",
    "\n",
    "wf.Sum = Sum(x=wf.DesignMatrix, axis=0)\n",
    "\n",
    "wf.Coeff = DotProduct(a=wf.PseudoInverse, b=wf.DiffEnergy, store=store)\n",
    "wf.DiffEnergyPerAtom = Divide(wf.DiffEnergy, wf.NumberOfAtoms)\n",
    "wf.FitEnergyDiff = DotProduct(a=wf.DesignMatrix, b=wf.Coeff)\n",
    "wf.FitEnergyDiffPerAtom = Divide(wf.FitEnergyDiff, wf.NumberOfAtoms)\n",
    "\n",
    "wf.MergeDataFrames.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da056782-1d66-4349-8de6-676732524583",
   "metadata": {},
   "outputs": [],
   "source": [
    "@as_macro_node([\"coefficients\", \"design_matrix\", \"r_bins\", \"diff_energy_per_atom\", \"fit_diff_energy_per_atom\", \"number_of_atoms\"])\n",
    "def FitDiffPotential(\n",
    "    file_path_0: str = \"ASSYST/Al_LDA.pckl.gz\",\n",
    "    file_path_1: str = \"ASSYST/Al_PBE.pckl.gz\",\n",
    "    r_min: float = 2.5,\n",
    "    r_max: float = 7,\n",
    "    num_points: int = 51,\n",
    "    max_row_index: int = -1,\n",
    "    store: bool = True,\n",
    "):\n",
    "\n",
    "    from pyiron_workflow import Workflow\n",
    "    from pyiron_nodes.atomistic.ml_potentials.fitting.linearfit import (\n",
    "        ReadPickledDatasetAsDataframe,\n",
    "    )\n",
    "    from pyiron_nodes.math import Linspace, Divide, DotProduct\n",
    "    from pyiron_nodes.atomistic.structure.calc import LinearInterpolationDescriptor\n",
    "    from pyiron_nodes.dataframe import (\n",
    "        MergeDataFrames,\n",
    "        GetRowsFromDataFrame,\n",
    "        GetColumnFromDataFrame,\n",
    "        ApplyFunctionToSeriesNew,\n",
    "    )\n",
    "    from pyiron_nodes.math import Subtract, PseudoInverse, Sum, DotProduct\n",
    "\n",
    "    wf = Workflow(\"assyst_linear_fit3\")\n",
    "\n",
    "    wf.ReadData = ReadPickledDatasetAsDataframe(\n",
    "        file_path=file_path_0,\n",
    "        compression=\"gzip\",\n",
    "    )\n",
    "\n",
    "    wf.ReadRefData = ReadPickledDatasetAsDataframe(\n",
    "        file_path=file_path_1,\n",
    "        compression=\"gzip\",\n",
    "    )\n",
    "\n",
    "    wf.Linspace = Linspace(x_min=r_min, x_max=r_max, num_points=num_points)\n",
    "\n",
    "    wf.MergeDataFrames = MergeDataFrames(\n",
    "        df1=wf.ReadData,\n",
    "        df2=wf.ReadRefData,\n",
    "        on=\"name\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    wf.LinearInterpolationDescriptor = LinearInterpolationDescriptor(r_bins=wf.Linspace)\n",
    "\n",
    "    wf.GetRowsFromDataFrame = GetRowsFromDataFrame(\n",
    "        df=wf.MergeDataFrames, max_index=max_row_index\n",
    "    )\n",
    "\n",
    "    wf.GetStructures = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=\"ase_atoms_x\"\n",
    "    )\n",
    "\n",
    "    wf.NumberOfAtoms = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=\"NUMBER_OF_ATOMS_x\"\n",
    "    )\n",
    "\n",
    "    wf.GetEnergy = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=\"energy_corrected_y\"\n",
    "    )\n",
    "\n",
    "    wf.GetRefEnergy = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=\"energy_corrected_x\"\n",
    "    )\n",
    "\n",
    "    wf.DesignMatrix = ApplyFunctionToSeriesNew(\n",
    "        series=wf.GetStructures,\n",
    "        function=wf.LinearInterpolationDescriptor,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    wf.DiffEnergy = Subtract(x=wf.GetEnergy, y=wf.GetRefEnergy)\n",
    "\n",
    "    wf.PseudoInverse = PseudoInverse(matrix=wf.DesignMatrix)\n",
    "\n",
    "    wf.Sum = Sum(x=wf.DesignMatrix, axis=0)\n",
    "\n",
    "    wf.Coeff = DotProduct(a=wf.PseudoInverse, b=wf.DiffEnergy, store=store)\n",
    "    wf.DiffEnergyPerAtom = Divide(wf.DiffEnergy, wf.NumberOfAtoms)\n",
    "    wf.FitEnergyDiff = DotProduct(a=wf.DesignMatrix, b=wf.Coeff)\n",
    "    wf.FitEnergyDiffPerAtom = Divide(wf.FitEnergyDiff, wf.NumberOfAtoms)\n",
    "\n",
    "    return wf.Coeff, wf.DesignMatrix, wf.Linspace, wf.DiffEnergyPerAtom, wf.FitEnergyDiffPerAtom, wf.NumberOfAtoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf27ef2-f0ab-440a-a997-4f76559948d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3a507-ac8f-4b10-9304-a0f3e4a4e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow(['assyst_data', 'neighbors1', 'assyst_linear_fit3', 'experiment', 'Workflow_4'], gui_layout=layout) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790f812-541a-4afa-a615-2039c95e9dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fc77e-12c6-4241-abba-f1240ef1a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from pyiron_workflow.graph.base import (Graph, graph_to_code, collapse_node, Nodes, Node, GraphEdge, \n",
    "get_code_from_graph, GraphNode, get_updated_graph, collapse_node, add_node, _remove_virtual_edges, _remove_edges_to_hidden_nodes, copy_graph)\n",
    "from pyiron_workflow.graph.graph_json import _save_graph, _load_graph\n",
    "from pyiron_workflow.graph.gui import GuiGraph, _mark_node_as_collapsed\n",
    "\n",
    "wf = Workflow('test')\n",
    "\n",
    "from pyiron_nodes.atomistic.structure.build import CubicBulkCell, Bulk\n",
    "from pyiron_nodes.atomistic.structure.transform import Repeat\n",
    "\n",
    "structure = CubicBulkCell(\"Al\")\n",
    "# structure = Bulk(\"Al\")\n",
    "\n",
    "graph = Graph(label=\"test\")\n",
    "graph += structure\n",
    "\n",
    "graph_c = collapse_node(graph, \"CubicBulkCell\")\n",
    "\n",
    "state = graph_c.__getstate__()  #[\"nodes\"][\"CubicBulkCell\"]\n",
    "del state[\"nodes\"][\"CubicBulkCell\"][\"graph\"]\n",
    "state[\"nodes\"][\"CubicBulkCell\"][\"node\"] = graph.nodes[\"CubicBulkCell\"][\"node\"].__getstate__()\n",
    "state[\"nodes\"][\"CubicBulkCell\"][\"node_type\"] = \"node\"\n",
    "state[\"edges\"][\"values\"] = []\n",
    "state\n",
    "\n",
    "nodes = Nodes().__setstate__(state[\"nodes\"])\n",
    "nodes\n",
    "#new_graph = Graph().__setstate__(state)\n",
    "\n",
    "\n",
    "\n",
    "#_save_graph(graph, overwrite=True)\n",
    "#_load_graph(\"test.json\")\n",
    "# print (get_code_from_graph(graph.nodes[\"CubicBulkCell\"].graph, sort_graph=True, use_node_default=False))\n",
    "# print(graph_to_code(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a068bd6-a380-4187-9265-574cb05321d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b67062-3623-4d6f-88e1-ac9ee872f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "structure = CubicBulkCell(\"Al\")\n",
    "repeat = Repeat()\n",
    "\n",
    "graph = Graph(label=\"test\")\n",
    "graph = add_node(graph, structure, label=\"CubicBulk\")\n",
    "graph = add_node(graph, repeat, label=\"repeat1\")\n",
    "graph += GraphEdge(source=\"CubicBulk\", target=\"repeat1\", sourceHandle=\"structure\", targetHandle=\"structure\")\n",
    "\n",
    "\n",
    "def compact_graph(graph: Graph):\n",
    "    graph = copy_graph(graph)\n",
    "    for k, node in graph.nodes.items():\n",
    "        # find macro nodes in the top level and collapse them\n",
    "        if (node.graph is not None) and (node.parent_id is None) and (node.import_path is not None):\n",
    "            print(\"collapse: \", k)\n",
    "            new_node = GraphNode(node=node.node, \n",
    "                                 id=node.id,\n",
    "                                 label=node.label, \n",
    "                                 expanded=False, \n",
    "                                 import_path=node.import_path, \n",
    "                                 node_type=node.node_type)\n",
    "            graph.nodes[k] = new_node\n",
    "            graph = collapse_node(graph, k)\n",
    "            \n",
    "    graph = get_updated_graph(graph)\n",
    "    return graph \n",
    "\n",
    "\n",
    "cg = compact_graph(graph)\n",
    "state = cg.__getstate__()\n",
    "# state[\"edges\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420554cb-f5af-420c-a0df-af2b51506f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncompact_graph_from_state(state):\n",
    "    graph = Graph(label=state[\"label\"])\n",
    "    for k, node_state in state[\"nodes\"].items():\n",
    "        if isinstance(node_state, dict):\n",
    "            # print(k, type(node_state))\n",
    "            graph_node = GraphNode().__setstate__(node_state)\n",
    "            if (graph_node.node is None) and (graph_node.import_path is not None):\n",
    "                node = Node().__setstate__(node_state[\"node\"])\n",
    "                graph = add_node(graph, node, label=node.label)\n",
    "                graph = _mark_node_as_collapsed(graph, node.label)\n",
    "            else:\n",
    "                graph +=graph_node\n",
    "\n",
    "    for edge_state in state[\"edges\"][\"values\"]:\n",
    "        print(edge_state)\n",
    "        graph += GraphEdge(**edge_state)\n",
    "\n",
    "    return graph\n",
    "\n",
    "new_graph = uncompact_graph_from_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a932411-2628-4a2f-a2cc-e9bb4ace5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow([new_graph]) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d19328-abd1-4e97-9771-3b926c998759",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef01f6-6d16-429a-aa0f-6a6732ad7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "GuiGraph(new_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a83b36-8f1b-4988-97b9-602a9fcc1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nodes().__setstate__(state[\"nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869abdf-e512-4e83-883b-c957079eb0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "GuiGraph(cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aedc4e6-7f44-4062-955b-50f5c56f68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(label=\"test\")\n",
    "\n",
    "state[\"nodes\"][\"CubicBulkCell\"][\"expanded\"] = False\n",
    "node = GraphNode().__setstate__(state[\"nodes\"][\"CubicBulkCell\"]) #[\"node\"])\n",
    "\n",
    "node = Node().__setstate__(state[\"nodes\"][\"CubicBulkCell\"][\"node\"])\n",
    "\n",
    "graph = add_node(graph, node, label=state[\"nodes\"][\"CubicBulkCell\"][\"label\"])\n",
    "node.expanded = False\n",
    "\n",
    "graph = collapse_node(graph, \"CubicBulkCell\")\n",
    "\n",
    "graph = get_updated_graph(graph)\n",
    "node = graph.nodes[\"CubicBulkCell\"]\n",
    "node.graph = None\n",
    "#node.node_type = \"node\"\n",
    "print(graph_to_code(graph))\n",
    "\n",
    "# _save_graph(graph, overwrite=True)\n",
    "# _load_graph(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464b0c8-e140-492d-bb4c-ce4e8534e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.__getstate__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58b095-8c42-409a-aac1-7fc288d1b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GuiGraph(get_updated_graph(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38750882-72cd-4665-bb39-fcb949e841d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow.graph.gui import GuiGraph\n",
    "\n",
    "GuiGraph(graph.nodes[\"CubicBulkCell\"].graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e9d52-6f6a-444b-9e8a-9f82022603bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"nodes\"][\"CubicBulkCell\"][\"node\"]\n",
    "Node().__setstate__(state[\"nodes\"][\"CubicBulkCell\"][\"node\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debda59f-b201-44ca-b2fe-503c6a51302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from pyiron_workflow.graph.base import Graph, graph_to_code, collapse_node, Nodes, Node\n",
    "from pyiron_workflow.graph.graph_json import _save_graph, _load_graph\n",
    "\n",
    "wf = Workflow('test')\n",
    "\n",
    "from pyiron_nodes.atomistic.structure.build import CubicBulkCell, Bulk\n",
    "\n",
    "#structure = CubicBulkCell(\"Al\")\n",
    "structure = Bulk(\"Al\")\n",
    "\n",
    "graph = Graph(label=\"test\")\n",
    "graph += structure\n",
    "\n",
    "state = graph.__getstate__() \n",
    "#del state[\"nodes\"][\"CubicBulkCell\"][\"graph\"]\n",
    "#state[\"nodes\"][\"CubicBulkCell\"][\"node\"] = graph.nodes[\"CubicBulkCell\"][\"node\"].__getstate__()\n",
    "#state[\"edges\"][\"values\"] = []\n",
    "#state\n",
    "\n",
    "nodes = Nodes().__setstate__(state[\"nodes\"])\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c694dd2-f052-4d24-b4ce-917be8fefc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow.graph.base import get_graph_from_wf\n",
    "from pyiron_workflow.graph.gui import GuiGraph\n",
    "from pyiron_workflow.graph.graph_json import _save_graph, _load_graph\n",
    "\n",
    "graph = get_graph_from_wf(wf, wf_outputs=[wf.structure], out_labels=[\"structure\"])\n",
    "\n",
    "# _save_graph(graph, overwrite=True)\n",
    "# _load_graph(\"test.json\")\n",
    "# GuiGraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1466be-8072-4725-a7e4-8b85a20f0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import as_macro_node\n",
    "\n",
    "@as_macro_node(\"figure\")\n",
    "def assyst_linear_fit3(\n",
    "    ReadPickledDatasetAsDataframe__file_path: str = \"ASSYST/Al_LDA.pckl.gz\",\n",
    "    ReadPickledDatasetAsDataframe__compression: str = \"gzip\",\n",
    "    ReadPickledDatasetAsDataframe_1__file_path: str = \"ASSYST/Al_PBE.pckl.gz\",\n",
    "    ReadPickledDatasetAsDataframe_1__compression: str = \"gzip\",\n",
    "    Linspace__x_min: float = 2.5,\n",
    "    Linspace__x_max: float = 7,\n",
    "    Linspace__num_points: int = 51,\n",
    "    MergeDataFrames__on: str = \"name\",\n",
    "    MergeDataFrames__how: str = \"inner\",\n",
    "    GetRowsFromDataFrame__max_index: int = -1,\n",
    "    GetColumnFromDataFrame_2__column_name: str = \"ase_atoms_x\",\n",
    "    GetColumnFromDataFrame_3__column_name: str = \"energy_corrected_y\",\n",
    "    GetColumnFromDataFrame_1__column_name: str = \"energy_corrected_x\",\n",
    "    ApplyFunctionToSeries_2__store: bool = True,\n",
    "    Sum__axis: int = 0,\n",
    "    DotProduct__store: bool = True,\n",
    "):\n",
    "\n",
    "    from pyiron_workflow import Workflow\n",
    "\n",
    "    wf = Workflow(\"assyst_linear_fit3\")\n",
    "\n",
    "    from pyiron_nodes.atomistic.ml_potentials.fitting.linearfit import (\n",
    "        ReadPickledDatasetAsDataframe,\n",
    "    )\n",
    "\n",
    "    wf.ReadPickledDatasetAsDataframe = ReadPickledDatasetAsDataframe(\n",
    "        file_path=ReadPickledDatasetAsDataframe__file_path,\n",
    "        compression=ReadPickledDatasetAsDataframe__compression,\n",
    "    )\n",
    "    from pyiron_nodes.atomistic.ml_potentials.fitting.linearfit import (\n",
    "        ReadPickledDatasetAsDataframe,\n",
    "    )\n",
    "\n",
    "    wf.ReadPickledDatasetAsDataframe_1 = ReadPickledDatasetAsDataframe(\n",
    "        file_path=ReadPickledDatasetAsDataframe_1__file_path,\n",
    "        compression=ReadPickledDatasetAsDataframe_1__compression,\n",
    "    )\n",
    "    from pyiron_nodes.math import Linspace\n",
    "\n",
    "    wf.Linspace = Linspace(\n",
    "        x_min=Linspace__x_min, x_max=Linspace__x_max, num_points=Linspace__num_points\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import MergeDataFrames\n",
    "\n",
    "    wf.MergeDataFrames = MergeDataFrames(\n",
    "        df1=wf.ReadPickledDatasetAsDataframe,\n",
    "        df2=wf.ReadPickledDatasetAsDataframe_1,\n",
    "        on=MergeDataFrames__on,\n",
    "        how=MergeDataFrames__how,\n",
    "    )\n",
    "    from pyiron_nodes.atomistic.structure.calc import LinearInterpolationDescriptor\n",
    "\n",
    "    \n",
    "    wf.LinearInterpolationDescriptor = LinearInterpolationDescriptor(r_bins=wf.Linspace)\n",
    "    from pyiron_nodes.dataframe import GetRowsFromDataFrame\n",
    "\n",
    "    wf.GetRowsFromDataFrame = GetRowsFromDataFrame(\n",
    "        df=wf.MergeDataFrames, max_index=GetRowsFromDataFrame__max_index\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import GetColumnFromDataFrame\n",
    "\n",
    "    wf.GetColumnFromDataFrame_2 = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=GetColumnFromDataFrame_2__column_name\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import GetColumnFromDataFrame\n",
    "\n",
    "    wf.GetColumnFromDataFrame_3 = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=GetColumnFromDataFrame_3__column_name\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import GetColumnFromDataFrame\n",
    "\n",
    "    wf.GetColumnFromDataFrame_1 = GetColumnFromDataFrame(\n",
    "        df=wf.GetRowsFromDataFrame, column_name=GetColumnFromDataFrame_1__column_name\n",
    "    )\n",
    "    from pyiron_nodes.dataframe import ApplyFunctionToSeriesNew\n",
    "\n",
    "    wf.ApplyFunctionToSeries_2 = ApplyFunctionToSeriesNew(\n",
    "        series=wf.GetColumnFromDataFrame_2,\n",
    "        function=wf.LinearInterpolationDescriptor,\n",
    "        store=ApplyFunctionToSeries_2__store,\n",
    "    )\n",
    "    from pyiron_nodes.math import Subtract\n",
    "\n",
    "    wf.Subtract = Subtract(x=wf.GetColumnFromDataFrame_1, y=wf.GetColumnFromDataFrame_3)\n",
    "    from pyiron_nodes.math import PseudoInverse\n",
    "\n",
    "    wf.PseudoInverse = PseudoInverse(matrix=wf.ApplyFunctionToSeries_2)\n",
    "    from pyiron_nodes.math import Sum\n",
    "\n",
    "    wf.Sum = Sum(x=wf.ApplyFunctionToSeries_2, axis=Sum__axis)\n",
    "    from pyiron_nodes.math import DotProduct\n",
    "\n",
    "    wf.DotProduct = DotProduct(\n",
    "        a=wf.PseudoInverse, b=wf.Subtract, store=DotProduct__store\n",
    "    )\n",
    "\n",
    "\n",
    "    return wf.DotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad85a31-b42b-47a4-b94f-68b65858e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assyst_linear_fit3().pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0865ba-8cad-4967-85ad-ebf13ed3ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx\n",
    "\n",
    "import calphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87f5db-0357-481b-9409-78fd2a73181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_nodes as pn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyiron_nodes.dataframe import ApplyFunctionToSeriesNew\n",
    "from pyiron_workflow import Workflow\n",
    "\n",
    "wf = Workflow(\"test\")\n",
    "\n",
    "structure = pn.atomistic.structure.build.CubicBulkCell('Al').run()\n",
    "\n",
    "series = pd.Series([structure, structure]) \n",
    "\n",
    "\n",
    "wf.node = pn.atomistic.structure.calc.LinearInterpolationDescriptor()\n",
    "\n",
    "wf.Apply_Function = ApplyFunctionToSeriesNew(\n",
    "    series=series,\n",
    "    function=wf.node,\n",
    "    store=False,\n",
    ")\n",
    "\n",
    "wf.Apply_Function.pull()\n",
    "# wf.node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08742f7d-5dad-4b51-be2f-b9ebbeba2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(node.kwargs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db595e24-ac0f-45ae-bfd0-8e7f3f825f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.Series([1,2]).apply(np.sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97258130-544a-4e16-bc8f-a0667216243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41ae1e-bd30-4c1d-891d-907af7448a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from structuretoolkit import get_neighbors, \n",
    "\n",
    "get_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea87011-615d-4121-a4bc-ad3de362fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_min = 0\n",
    "x_max = 1\n",
    "steps = 11\n",
    "x, dx = np.linspace(x_min, x_max, steps, retstep=True)\n",
    "y = np.zeros(steps)\n",
    "\n",
    "x0 = 0.3001\n",
    "i_left = int((x0 - x_min) * steps) \n",
    "\n",
    "w = (x0 - x[i_left])/dx\n",
    "print (i_left, x, w)\n",
    "y[i_left] += 1-w\n",
    "y[i_left + 1] = w\n",
    "x[i_left], x[i_left+1]\n",
    "np.sum(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28bcdc-4401-4ddb-b5ef-8780c94d892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_nodes as pn\n",
    "\n",
    "pn.atomistic.structure.build.CubicBulkCell('Al').run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be12613-6cbf-4d2d-8ad7-c33826159f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pyiron_nodes as pn\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def gaussian_weighted_histogram(data, bins=50, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Compute a Gaussian-weighted histogram for a list of floats.\n",
    "\n",
    "    Parameters:\n",
    "        data (list or np.ndarray): Input data (list of floats).\n",
    "        bins (int): Number of bins for the histogram.\n",
    "        sigma (float): Standard deviation of the Gaussian kernel.\n",
    "\n",
    "    Returns:\n",
    "        bin_centers (np.ndarray): Centers of the histogram bins.\n",
    "        weighted_histogram (np.ndarray): Gaussian-weighted histogram values.\n",
    "    \"\"\"\n",
    "    # Create histogram bins\n",
    "    bin_edges = np.linspace(min(data), max(data), bins + 1)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Initialize the weighted histogram\n",
    "    weighted_histogram = np.zeros_like(bin_centers)\n",
    "\n",
    "    # Apply Gaussian weighting for each data point\n",
    "    for x in data:\n",
    "        weights = norm.pdf(bin_centers, loc=x, scale=sigma)\n",
    "        weighted_histogram += weights\n",
    "\n",
    "    return bin_centers, weighted_histogram\n",
    "\n",
    "\n",
    "bulk = pn.atomistic.structure.build.Bulk('Al', cubic=True)\n",
    "\n",
    "bulk.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13125bfe-cd2b-4265-b431-402379e6996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow(['assyst',  'linearfit2', 'landau2', 'svd_solver', 'linear_fit',  'plot_sin', 'supercell_conv']) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419a726-ca89-4c59-9ad6-47b02dbe59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d6011-2845-447b-99f2-183777aa5a80",
   "metadata": {},
   "source": [
    "ToDo (key priorities):\n",
    "- renaming of labels\n",
    "- grouping with renaming of group names\n",
    "- sorting and search in node tree\n",
    "- js gui input - sign fails (e.g. -1) gives json reading error (solved in gui.py)\n",
    "- run only needed nodes (where no hashed output is available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b42cbe-ad07-4f38-b717-46a700394379",
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bd764-13ac-4908-9a1e-d89334649201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "my_str = \"{\\\"label\\\":\\\"Identity\\\",\\\"handle\\\":0,\\\"value\\\":\\\"-1\\\"}\"\n",
    "\n",
    "json.loads(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96da94-9d72-40e5-a0bd-addf5541a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lst = []\n",
    "for i in [[0], [1,1]]:\n",
    "    lst += list(np.array(i))\n",
    "lst\n",
    "\n",
    "np.sqrt(0.000496688)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e83ebc-2f4c-4f27-886e-6726d71f6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.append()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ab9c4-30dd-4a9e-8153-92311bf0ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow, as_macro_node\n",
    "import pyiron_nodes as pn\n",
    "\n",
    "pn.atomistic.ml_potentials.fitting.linear_ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c79bbb-cf04-4c8b-9cbc-d58a1c277afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@as_macro_node(\"phase_data\")\n",
    "def ComputPhaseDiagram(filename: str=\"MgCaFreeEnergies.pckl.gz\", T_min:int=300, T_max:int=1100, T_steps=20):\n",
    "    wf = Workflow(\"PhaseDiagram\")\n",
    "    wf.read_data = pn.utilities.ReadDataFrame(filename=filename, compression=\"gzip\")\n",
    "    wf.phases_from_df = pn.atomistic.thermodynamics.landau.phases.PhasesFromDataFrame(dataframe=wf.read_data)\n",
    "    wf.temperatures = pn.math.Linspace(x_min=T_min, x_max=T_max, num_points=T_steps, endpoint=True)\n",
    "    wf.calc_phase_diagram = pn.atomistic.thermodynamics.landau.plot.CalcPhaseDiagram(phases=wf.phases_from_df.outputs.phase_list, temperatures=wf.temperatures, refine=True)\n",
    "    return wf.calc_phase_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab841b1-55de-4684-8634-791abeb12cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ComputPhaseDiagram().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7826373-d048-44b8-b2bb-048404dbe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyace import PyACECalculator\n",
    "import pyiron_nodes\n",
    "from pyiron_workflow import Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5fbcb-f42c-4987-a7e5-1d842ca7ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow('linearfit2')\n",
    "\n",
    "wf.ParameterizePotentialConfig = pyiron_nodes.atomistic.ml_potentials.fitting.linearfit.ParameterizePotentialConfig(number_of_functions_per_element=100) \n",
    "wf.ReadPickledDatasetAsDataframe = pyiron_nodes.atomistic.ml_potentials.fitting.linearfit.ReadPickledDatasetAsDataframe(file_path=\"mgca.pckl.tgz\") \n",
    "wf.SplitTrainingAndTesting = pyiron_nodes.atomistic.ml_potentials.fitting.linearfit.SplitTrainingAndTesting(data_df=wf.ReadPickledDatasetAsDataframe) \n",
    "wf.RunLinearFit = pyiron_nodes.atomistic.ml_potentials.fitting.linearfit.RunLinearFit(df_test=wf.SplitTrainingAndTesting.outputs.df_testing, \n",
    "                                                                                      df_train=wf.SplitTrainingAndTesting.outputs.df_training, potential_config=wf.ParameterizePotentialConfig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36130a29-c134-4a7f-a1e5-c1f6cfbf358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = wf.RunLinearFit.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aee5d3-38fd-46bb-acd8-4684321ef2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ace = PyACECalculator(fit)\n",
    "ace.basis.basis_coeffs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc94f0-d1c4-4842-a4e2-0889a141229f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0d690-7102-4006-aa26-781033b7e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.atomistic.structure.build import Bulk\n",
    "\n",
    "structure = Bulk(\"Ca\", cubic=True).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b220643-4cba-4507-a407-3127a8c3dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ace.calculate(atoms=structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac14c8-9893-4147-8cb8-555c4aaff09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd81338-b341-427b-8716-c79b682a69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = wf.SplitTrainingAndTesting.outputs.df_testing.value\n",
    "potential_config = wf.ParameterizePotentialConfig.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ceab9-4ce4-4e16-aa7b-f2348d269978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyace.linearacefit import LinearACEFit, LinearACEDataset\n",
    "from pyace import create_multispecies_basis_config\n",
    "\n",
    "from pyiron_snippets.logger import logger\n",
    "\n",
    "logger.setLevel(30)\n",
    "verbose = False\n",
    "\n",
    "elements_set = set()\n",
    "for at in df_train[\"ase_atoms\"]:\n",
    "    elements_set.update(at.get_chemical_symbols())\n",
    "\n",
    "elements = sorted(elements_set)\n",
    "potential_config.elements = elements\n",
    "potential_config_dict = potential_config.to_dict()\n",
    "\n",
    "bconf = create_multispecies_basis_config(potential_config_dict)\n",
    "\n",
    "train_ds = LinearACEDataset(bconf, df_train)\n",
    "train_ds.construct_design_matrix(verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979b069-28c5-42b7-bd13-75254cf7840a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d3e51-5bc9-41a5-a929-bb4f7741604e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ef8eb-734b-4fae-96dd-5d04c976308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = train_ds.design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d126b71-4ce6-4f0c-82bd-bb17bc51d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab\n",
    "\n",
    "# np.linalg.svd(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da8230-5c5e-4558-892c-d2efc9bc30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "u, s, vh = np.linalg.svd(mat, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061ddd7-46a5-4793-b6d3-31b602bc609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vh[96]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cfe938-b15f-4770-98b0-e5a90a8bed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_mat = np.zeros(mat.shape)\n",
    "norm_list = []\n",
    "for i in range(len(s)):\n",
    "    svd_mat += np.outer(u.T[i], vh[i]) * s[i]\n",
    "    norm_list.append(np.linalg.norm(svd_mat - mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71954f20-5b70-4155-bd9c-eabe2850f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(norm_list, label='norm')\n",
    "plt.plot(s, label='s')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31946bf-bbdd-4467-9329-13b5fae85daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.energy_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac80fe1f-2b1c-4cc8-89b0-d5c349006c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference data\n",
    "training_number_of_atoms = df_train.NUMBER_OF_ATOMS.to_numpy()\n",
    "training_energies = df_train.energy_corrected.to_numpy()\n",
    "\n",
    "np.sum(training_number_of_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243372bd-8f8c-4e83-929f-b38e4d9990d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148b5d0-32a2-443b-a4dd-d3448a291524",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.construct_target_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d85c3b-dc13-4eaa-84ac-32bb2cab41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds.get_energies_per_atom())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949fe45-fe1b-4f95-89ca-18d1acc5bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.get_energies_per_atom??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95239e58-2e50-43aa-ac21-418f764483c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.get_target_vector??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3233e-6257-4928-bc1c-b03fa8410217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
