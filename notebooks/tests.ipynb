{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.evaluation='unsafe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/Users/joerg/git_libs/pyiron_core\")\n",
    "sys.path.insert(0, \"/Users/joerg/git_libs/pyiron_database\")\n",
    "sys.path.insert(0, \"/Users/joerg/git_libs/landau\")\n",
    "\n",
    "from pyiron_workflow.graph import gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f1a5f4935244f086c6d2dc4659a402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Tab(children=(ReactFlowWidget(layout=Layout(height='800px', width='1200px')), ReactFlâ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = gui.PyironFlow(['assyst', 'calphy2', 'linearfit2', 'landau2']) # 'calphy', 'landau',\n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mxx\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_workflow.graph._graph_operations as go\n",
    "from pyiron_workflow import as_function_node\n",
    "from pyiron_workflow.graph import base, gui\n",
    "from pyiron_workflow.simple_workflow import Workflow\n",
    "import pyiron_nodes as pn\n",
    "# import landau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_database.instance_database as idb\n",
    "import pyiron_database.obj_reconstruction.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.thermodynamics.cp_models import GibbsData, DataVector\n",
    "from dataclasses import dataclass, field\n",
    "from pyiron_workflow import as_out_dataclass_node\n",
    "\n",
    "@dataclass\n",
    "# @as_out_dataclass_node\n",
    "class GibbsData:\n",
    "    temperature: DataVector = field(default_factory=lambda: DataVector(\"Temperature\", unit=\"K\"))\n",
    "\n",
    "\n",
    "# GibbsData()\n",
    "# DataVector(\"Temperature\", unit=\"K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "plt.plot(x, x)\n",
    "plt.xlabel('x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow(['Gibbs_macro'])\n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "import pyiron_nodes.atomistic.ml_potentials.fitting.linear_ace as la\n",
    "\n",
    "wf = Workflow('Linear Ace Model')\n",
    "wf.potential_config = la.PotentialConfig(elements=[\"Al\"])\n",
    "wf.empty_basis = la.CreateEmptyBasisFunctions(wf.potential_config)\n",
    "wf.load_dataset = la.ReadPickledDatasetAsDataframe(file_path = \"dataset.pckl.gzip\")\n",
    "wf.split_dataset = la.SplitTrainingAndTesting(df = wf.load_dataset.outputs.df, training_frac=0.5)\n",
    "wf.create_descriptors = la.PrepareLinearACEdataset(bconf = wf.empty_basis,\n",
    "                                                df_train = wf.split_dataset.outputs.df_train,\n",
    "                                                df_test=wf.split_dataset.outputs.df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level to DEBUG\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow.graph import gui\n",
    "\n",
    "pf = gui.PyironFlow(['flow_macro', 'Lammps', 'iterCellSize', 'elastic_m3gnet',  'minimize', 'assyst', 'calphy', 'ase_fit', 'assyst2', 'linearfit',  'universal_potential', 'landau']) # 'calphy', 'landau',\n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_nodes.atomistic.property.calphy as calphy\n",
    "import pyiron_nodes as pn\n",
    "\n",
    "wf = Workflow(\"macro\")\n",
    "wf.tolerance = calphy.Tolerance(solid_fraction=0, liquid_fraction=0.05)\n",
    "wf.input = calphy.InputClass(n_equilibration_steps=2500, n_switching_steps=2500)\n",
    "wf.structure = pn.atomistic.structure.build.CubicBulkCell('Ni', cell_size=5)\n",
    "wf.potential = pn.atomistic.engine.lammps.Potential(structure=wf.structure, index=0)\n",
    "# wf.solid = calphy.SolidFreeEnergyWithTemperature(inp=wf.input, structure=wf.structure, potential=wf.potential, store=False)\n",
    "wf.liquid = calphy.LiquidFreeEnergyWithTemperature(inp=wf.input, structure=wf.structure, potential=wf.potential, store=True)\n",
    "\n",
    "wf.liquid.pull()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorpotential.calculator import grace_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "x, y = np.array([[10, 160.98], [20, 68.01], [100, 25.43], [200, 20.35], [1000, 16.45]]).T\n",
    "plt.plot(x, y)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba list  tensorpotential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorpotential.calculator import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba env list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_nodes.atomistic.calculator.generic import ApplyEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -c \"import matgl; matgl.clear_cache()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "basis = pf.graph.nodes[\"RunLinearFit\"].node.outputs.basis.value\n",
    "d = pickle.dumps(basis)\n",
    "\n",
    "pickle.loads(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_database.obj_reconstruction.util import serialize_obj\n",
    "\n",
    "serialize_obj(basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(basis.__getstate__(), dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_obj??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node = pf.graph.nodes[\"PrepareLinearACEdataset\"].node\n",
    "node.outputs.test_ds.value.df\n",
    "# idb.store_node_outputs(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from collections.abc import Generator, Sequence\n",
    "from itertools import product\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Stoichiometry(Sequence):\n",
    "    stoichiometry: tuple[dict[str, int]]\n",
    "\n",
    "    @property\n",
    "    def elements(self) -> set[str]:\n",
    "        \"\"\"Set of elements present in stoichiometry.\"\"\"\n",
    "        e = set()\n",
    "        for s in self.stoichiometry:\n",
    "            s = e.union(s.keys())\n",
    "        return s\n",
    "\n",
    "    # FIXME: Self only availabe in >=3.11\n",
    "    def __add__(self, other: \"Stoichiometry\") -> \"Stoichiometry\":\n",
    "        \"\"\"Extend underlying list of stoichiometries.\"\"\"\n",
    "        return Stoichiometry(self.stoichiometry + other.stoichiometry)\n",
    "\n",
    "    def __or__(self, other: \"Stoichiometry\") -> \"Stoichiometry\":\n",
    "        \"\"\"Inner product of underlying stoichiometries.\n",
    "\n",
    "        Must not share elements with other stoichiometry.\"\"\"\n",
    "        assert self.elements.isdisjoint(\n",
    "            other.elements\n",
    "        ), \"Can only or stoichiometries of different elements!\"\n",
    "        s = ()\n",
    "        for me, you in zip(self.stoichiometry, other.stoichiometry):\n",
    "            s += (me | you,)\n",
    "        return Stoichiometry(s)\n",
    "\n",
    "    def __mul__(self, other: \"Stoichiometry\") -> \"Stoichiometry\":\n",
    "        \"\"\"Outer product of underlying stoichiometries.\n",
    "\n",
    "        Must not share elements with other stoichiometry.\"\"\"\n",
    "        assert self.elements.isdisjoint(\n",
    "            other.elements\n",
    "        ), \"Can only multiply stoichiometries of different elements!\"\n",
    "        s = ()\n",
    "        for me, you in product(self.stoichiometry, other.stoichiometry):\n",
    "            s += (me | you,)\n",
    "        return Stoichiometry(s)\n",
    "\n",
    "    # Sequence Impl'\n",
    "    def __getitem__(self, index: int) -> dict[str, int]:\n",
    "        return self.stoichiometry[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.stoichiometry)\n",
    "\n",
    "\n",
    "def ElementInput(\n",
    "    element: str,\n",
    "    min_ion: int = 1,\n",
    "    max_ion: int = 10,\n",
    "    step_ion: int = 1,\n",
    ") -> Stoichiometry:\n",
    "    stoichiometry = Stoichiometry(\n",
    "        tuple({element: i} for i in range(min_ion, max_ion + 1, step_ion))\n",
    "    )\n",
    "    return stoichiometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElementInput('Al') * ElementInput('Li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.serialize_obj(node.outputs.generic.value);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_database.generic_storage.hdf5_storage import HDF5Storage\n",
    "import numpy as np\n",
    "\n",
    "output_path = \"mytest.h5\"\n",
    "with HDF5Storage(output_path, \"w\") as storage:\n",
    "    # storage['out'] = dict(a=np.array([10])) # util.serialize_obj(node.outputs.generic.value)\n",
    "    storage['out'] = 'a' #dict(a=[10])\n",
    "    storage['dict'] = dict(a=[10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_database.generic_storage.hdf5_storage import HDF5Storage\n",
    "\n",
    "output_path = \"mytest.h5\"\n",
    "with HDF5Storage(output_path, \"w\") as storage:\n",
    "    storage['out'] = pickle_dump(util.serialize_obj(node.outputs.generic.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_database.generic_storage.hdf5_storage import HDF5Storage\n",
    "\n",
    "output_path = \"mytest.h5\"\n",
    "with HDF5Storage(output_path, \"r\") as storage:\n",
    "    print([v for v in storage.keys()])\n",
    "    print(util.deserialize_obj(pickle_load(storage['out'])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import codecs\n",
    "\n",
    "def pickle_dump(obj):\n",
    "    return codecs.encode(pickle.dumps(obj), \"base64\").decode()\n",
    "\n",
    "\n",
    "def pickle_load(buf):\n",
    "    return pickle.loads(codecs.decode(buf.encode(), \"base64\"))\n",
    "\n",
    "len(pickle_dump(util.serialize_obj(node.outputs.generic.value.forces)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.outputs.generic.value.forces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.outputs.generic.value.__getstate__();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "pickle.dumps(node.outputs.sefs_container.value.__getstate__()['structures'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.outputs.generic.value.__getstate__().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.get_import_path_from_type(node.outputs.generic.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import is_dataclass\n",
    "\n",
    "is_dataclass(node.outputs.generic.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "len(pickle.dumps(util.serialize_obj(node.outputs.generic.value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = util.serialize_obj(node.outputs.generic.value)\n",
    "\n",
    "dc = util.deserialize_obj(state)\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "\n",
    "Atoms().__getstate__(), util.recreate_type(*util.get_type(Atoms()))()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.atomistic.calculator.data.OutputCalcMD.__closure__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pn.atomistic.calculator.data.OutputCalcMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Test:\n",
    "    a: str = 'a'\n",
    "\n",
    "Test().__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import is_dataclass, dataclass\n",
    "\n",
    "is_dataclass(node.outputs.generic.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "imp_path = util.get_type(np.array([1,2]))\n",
    "util.recreate_type(*imp_path)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2].__getstate__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dumps(node.outputs.generic.value.__getstate__());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_path = util.get_type(node.outputs.generic.value)\n",
    "util.recreate_type(*import_path)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.outputs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.outputs['t']._value = [1]\n",
    "node.outputs['t'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.outputs['t']._value = [1,2]\n",
    "node.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idb.restore_node_outputs(node)\n",
    "node.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('int')('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyiron_potentialfit.assyst.calculations as pcalc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not running the graph rather than the workflow. Graph is much more powerful and includes serialization and subgraphs? This works already! Does not yet have concept of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow('test')\n",
    "wf.bulk = pn.atomistic.structure.build.Bulk('Al', cubic=True)\n",
    "wf.repeat = pn.atomistic.structure.transform.Repeat(wf.bulk, repeat_scalar=1)\n",
    "wf.repeat2 = pn.atomistic.structure.transform.Repeat(wf.repeat, repeat_scalar=1)\n",
    "# wf.lammps = pn.atomistic.engine.lammps.Code1(structure=wf.repeat2)\n",
    "\n",
    "full_graph = base.get_full_graph_from_wf(wf)\n",
    "sub_graph = base._get_subgraph(full_graph, [1]) # collaps if node is macro node\n",
    "\n",
    "# TODO: \n",
    "# - extend output option (include all child node outputs)\n",
    "# - substitute selected nodes with ports having outside connections by a single virtual (graph-only) node\n",
    "# - add parent group as graph node\n",
    "# - make all inner nodes to child nodes of the parent group\n",
    "# - create node object for the parent group\n",
    "\n",
    "base.GuiGraph(full_graph, full_graph=True, height=400)\n",
    "# node = base.graph_to_node(sub_graph)\n",
    "# node\n",
    "# node.outputs, sub_graph.label, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# - extend output option (include all child node outputs)\n",
    "# - substitute selected nodes with ports having outside connections by a single virtual (graph-only) node\n",
    "# - add parent group as graph node\n",
    "# - make all inner nodes to child nodes of the parent group\n",
    "# - create node object for the parent group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph.nodes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = base.graph_to_node(sub_graph)\n",
    "node.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.get_externally_connected_input_ports(sub_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.get_non_default_input(sub_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.graph_to_node(sub_graph).outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph = base.create_group(full_graph, [0,1], label=\"subgraph\")\n",
    "new_graph.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: Make sure that all operations regarding virtual nodes and edges are encapsulated to not affect any other groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(\"test\")\n",
    "wf.bulk = pn.atomistic.structure.build.Bulk(\"Al\", cubic=True)\n",
    "wf.repeat = pn.atomistic.structure.transform.Repeat(wf.bulk, repeat_scalar=1)\n",
    "wf.repeat2 = pn.atomistic.structure.transform.Repeat(wf.repeat, repeat_scalar=1)\n",
    "wf.lammps = pn.atomistic.engine.lammps.Code1(structure=wf.repeat2)\n",
    "\n",
    "full_graph = base.get_full_graph_from_wf(wf)\n",
    "\n",
    "new_graph = base.create_group(full_graph, [0, 1, 2], label=\"subgraph\")\n",
    "\n",
    "new_graph.nodes[\"subgraph\"].expanded = True\n",
    "new_graph.nodes[\"lammps\"].expanded = False\n",
    "\n",
    "# True, True gives error\n",
    "\n",
    "new_graph = base.get_updated_graph(new_graph)\n",
    "\n",
    "base.GuiGraph(new_graph, full_graph=True, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = base._remove_virtual_nodes(new_graph, parent_label='lammps')\n",
    "g = base._remove_virtual_nodes(g, parent_label='subgraph')\n",
    "g = base.remove_hidden_nodes(g, \"lammps\")\n",
    "g.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph.__getstate__()['nodes']['subgraph']['graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph.__getstate__()['nodes']['lammps']['node']['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base._save_graph(new_graph2, \"new_graph2.json\")\n",
    "loaded_graph = base._load_graph(\"new_graph2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.display_gui_data(new_graph2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph = base.create_group(full_graph, [0,1], label=\"subgraph\")\n",
    "new_graph = base.move_parent_nodes_to_top(new_graph)\n",
    "new_graph.nodes[\"subgraph\"].expanded = True\n",
    "new_graph = base.get_updated_graph(new_graph)\n",
    "\n",
    "# new_graph0 = base.collapse_node(new_graph, \"subgraph\")\n",
    "# new_graph = base.expand_node(new_graph, \"subgraph\")\n",
    "# new_graph1 = base._remove_virtual_edges(new_graph0)\n",
    "# new_graph2 = base._remove_edges_to_hidden_nodes(new_graph1)\n",
    "# new_graph = base._remove_virtual_nodes(new_graph, reconnect_edges=True, parent_label=\"subgraph\")\n",
    "# new_graph = base._remove_virtual_nodes(new_graph, reconnect_edges=True, parent_label=\"lammps\")\n",
    "# new_graph = base.update_execution_graph(new_graph)\n",
    "\n",
    "new_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph0.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- remove duplicate edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow.graph import gui\n",
    "\n",
    "pf = gui.PyironFlow(['flow_macro', 'Code1', 'iterCellSize', 'elastic_m3gnet',  'minimize', 'calphy', 'assyst']) \n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Hashing (load and store output)\n",
    "- Caching?\n",
    "- identify closures (do not run them)\n",
    "- unfinished node states\n",
    "- Static as default for Lammps\n",
    "- \n",
    "- store error for iter when non-json object (fix)\n",
    "- allow for automatic array notation as input and outputs (like numpy, at least for structure and DataClasses?)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "elements = ['Al', 'Li']\n",
    "stoichiometry=[1, 2]\n",
    "max_atoms = 10\n",
    "\n",
    "\n",
    "ions = filter(lambda x: 0 < sum(x) <= max_atoms, product(stoichiometry, repeat=len(elements)))\n",
    "\n",
    "# print(list(ions))\n",
    "\n",
    "el_list, n_lst = [], []\n",
    "for n_ions in ions:\n",
    "    elements, num_ions = zip(*((el, ni) for el, ni in zip(elements, n_ions) if ni > 0))\n",
    "    el_list.append(elements)\n",
    "    n_lst.append(num_ions)\n",
    "\n",
    "el_list, n_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "el, nums = zip(*((el, ni) for el, ni in zip(elements, num_ions) if ni > 0))\n",
    "el, nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.atomistic.assyst.structures.SpaceGroupInputUnary.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.atomistic.calculator.data.InputCalcMD.__getstate__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SpaceGroupInput:\n",
    "    # def __post_init__(self):\n",
    "    #     if self.stoichiometry is None or len(self.stoichiometry) == 0:\n",
    "    #         self.stoichiometry = list(range(1, self.max_atoms + 1))\n",
    "    #     if self.spacegroups is None:\n",
    "    #         self.spacegroups = list(range(1,231))\n",
    "\n",
    "    elements: list[str]\n",
    "    max_atoms: int = 10\n",
    "    stoichiometry: list[int] | list[tuple[int, ...]] | None = None\n",
    "    spacegroups: list[int] | None = None\n",
    "\n",
    "    # can be either a single cutoff distance or a dictionary mapping chemical\n",
    "    # symbols to min *radii*; you need to half the value if you go from using a\n",
    "    # float to a dict\n",
    "    min_dist: float | dict[str, float] | None = None\n",
    "\n",
    "    # FIXME: just to restrict number of structures during testing\n",
    "    max_structures: int = 20\n",
    "\n",
    "SpaceGroupInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk = pf.graph.nodes['Bulk'].node\n",
    "bulk.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow('elastic')\n",
    "wf.bulk = pn.atomistic.structure.build.CubicBulkCell('Al')\n",
    "wf.input_elastic_tensor = pn.atomistic.property.elastic.InputElasticTensor()\n",
    "wf.symmetry_analysis = pn.atomistic.property.elastic.SymmetryAnalysis(structure=wf.bulk, parameters=wf.input_elastic_tensor)\n",
    "wf.structures = pn.atomistic.property.elastic.GenerateStructures(structure=wf.bulk, analysis=wf.symmetry_analysis, parameters=wf.input_elastic_tensor)\n",
    "wf.calc = pn.atomistic.engine.lammps.CalcStatic()\n",
    "#wf.engine = pn.atomistic.engine.lammps.Lammps(structure=wf.bulk, calculator=wf.calc)\n",
    "# wf.add_energies = pn.atomistic.property.elastic.AddEnergies(structure_container=wf.structures, engine=wf.engine)\n",
    "\n",
    "wf.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import as_inp_dataclass_node, as_out_dataclass_node\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@as_out_dataclass_node\n",
    "# @dataclass\n",
    "class OutputElasticSymmetryAnalysis:\n",
    "    SGN: int = 0\n",
    "    v0: float = 0.0\n",
    "    LC: int = 1\n",
    "    Lag_strain_list: list = field(default_factory=lambda: [])\n",
    "    epss: np.ndarray = field(default_factory=lambda: np.zeros(0))\n",
    "\n",
    "out = OutputElasticSymmetryAnalysis()#.dataclass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@as_out_dataclass_node\n",
    "class OutputCalcMD:\n",
    "    energies_pot: list | np.ndarray = field(\n",
    "        default_factory=lambda: np.array([])\n",
    "    )\n",
    "\n",
    "    energies_kin: list | np.ndarray = field(\n",
    "        default_factory=lambda: np.array([])\n",
    "    )\n",
    "    SGN: int = 0\n",
    "    v0: float = 0.0\n",
    "    LC: int = 1    \n",
    "\n",
    "OutputCalcMD().dataclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.atomistic.property.elastic.DataStructureContainer()   # OutputElasticAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.atomistic.property.elastic.OutputElasticSymmetryAnalysis() #bulk.run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_label = 'iterate_1'\n",
    "macro_node = pf.graph.nodes[macro_label].node\n",
    "# macro_graph = base.get_graph_from_macro_node(macro_node)\n",
    "\n",
    "out_list = macro_node.outputs.out_lst.value\n",
    "\n",
    "def ExtractList(out_list, label, flatten=True):\n",
    "    import numpy as np\n",
    "    \n",
    "    collect = np.array([out.__getattribute__(label) for out in out_list])\n",
    "    if flatten:\n",
    "        collect = collect.flatten()\n",
    "    return collect\n",
    "\n",
    "\n",
    "ExtractList(out_list, 'energies_pot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_node.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(macro_graph.nodes[\"Potential\"].node.inputs.structure.value.node.label), (macro_graph.nodes[\"Potential\"].node.inputs.structure.value.value.node.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(macro_graph.nodes[\"InitLammps\"].node.inputs.calculator.value.node.label), (macro_graph.nodes[\"InitLammps\"].node.inputs.calculator.value.value.node.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect inner node input directly with outer node, eliminate in execution macro input port\n",
    "for graph_node in macro_graph.nodes.values():\n",
    "    values = graph_node.node.inputs.data['value']\n",
    "    labels = graph_node.node.inputs.data['label']\n",
    "    for port_label, port_value in zip(labels, values):\n",
    "        # print('label: ', port_label)\n",
    "        if isinstance(port_value, (base.Port)):\n",
    "            # print(port_label, type(port_value.value))\n",
    "            if isinstance(port_value.value, (base.Port)):\n",
    "                print('double: ', port_value.value.label, port_value.value.node.label)\n",
    "                graph_node.node.inputs.__setattr__(port_label, port_value.value) \n",
    "\n",
    "# macro_graph.nodes['Potential'].node.inputs.structure.value.value\n",
    "pf.graph.nodes[\"Bulk\"].node.run()\n",
    "pf.graph.nodes[\"Potential\"].node.run()\n",
    "base.run_macro_node(macro_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_graph.nodes[\"ListPotentials\"].node.inputs.structure.value.value.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_node.inputs.structure.value.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.graph.nodes['CubicBulkCell'].node.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.graph.nodes['CubicBulkCell'].node.node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_macro_node(macro_node):\n",
    "    macro_graph = base.get_graph_from_macro_node(macro_node)\n",
    "    \n",
    "    output_nodes = list()\n",
    "    for edge in macro_graph.edges:\n",
    "        if f'va_o_{macro_node.label}__' in edge.target:\n",
    "            output_nodes.append(edge.source)\n",
    "    \n",
    "    outputs = list() \n",
    "    for out_label in set(output_nodes):\n",
    "        print(f'output node {out_label} of macro {macro_node.label}')\n",
    "        outputs.append(base.pull_node(macro_graph, out_label)) # use graph theory to avoid recalculating nodes (or use ready)\n",
    "\n",
    "    if len(outputs) == 1:\n",
    "        return outputs[0]\n",
    "    else:\n",
    "        return set(outputs)\n",
    "\n",
    "macro_node = pf.graph.nodes['CubicBulkCell'].node\n",
    "run_macro_node(macro_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.graph.nodes['CubicBulkCell'].node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.graph.nodes['bulk'].node.inputs.name.value.value  # input port of macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.graph.nodes['bulk'].node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.graph.nodes['Plot3d'].node.inputs.structure.value.value #.name.value.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base._graph_to_gui(sub_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Subgraph(structure, ):\n",
    "\n",
    "    from pyiron_workflow import Workflow\n",
    "    import pyiron_nodes\n",
    "\n",
    "    wf = Workflow('subgraph')\n",
    "\n",
    "    wf.Repeat = pyiron_nodes.atomistic.structure.transform.Repeat(structure=structure) \n",
    "    wf.Repeat_2 = pyiron_nodes.atomistic.structure.transform.Repeat(structure=wf.Repeat) \n",
    "    wf.Plot3d = pyiron_nodes.atomistic.structure.view.Plot3d(structure=structure) \n",
    "\n",
    "    return wf.Repeat_2\n",
    "\n",
    "structure = pn.atomistic.structure.build.Bulk(\"Al\", cubic=True).run()\n",
    "Subgraph(structure=structure).pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(structure=None, repeat_scalar=1):\n",
    "    from pyiron_workflow import Workflow\n",
    "    import pyiron_nodes\n",
    "\n",
    "    wf = Workflow(\"subgraph\")\n",
    "\n",
    "    # wf.va_i_subgraph__structure = __main__.InputNode()\n",
    "    wf.Repeat = pyiron_nodes.atomistic.structure.transform.Repeat(structure=structure, repeat_scalar=repeat_scalar)\n",
    "    wf.Repeat_2 = pyiron_nodes.atomistic.structure.transform.Repeat(structure=wf.Repeat)\n",
    "    wf.Plot3d = pyiron_nodes.atomistic.structure.view.Plot3d(structure=structure)\n",
    "\n",
    "    return wf.Repeat_2.pull()\n",
    "   \n",
    "structure = pn.atomistic.structure.build.Bulk(\"Al\", cubic=True).run()\n",
    "my_func(structure=structure, repeat_scalar=2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = pn.atomistic.structure.build.Bulk(\"Al\", cubic=True).run()\n",
    "import pyiron_nodes\n",
    "\n",
    "wf = Workflow(\"subgraph\")\n",
    "\n",
    "# wf.va_i_subgraph__structure = __main__.InputNode()\n",
    "wf.Repeat = pyiron_nodes.atomistic.structure.transform.Repeat(structure=structure)\n",
    "wf.Repeat_2 = pyiron_nodes.atomistic.structure.transform.Repeat(structure=wf.Repeat, repeat_scalar=1)\n",
    "wf.Plot3d = pyiron_nodes.atomistic.structure.view.Plot3d(structure=structure)\n",
    "\n",
    "wf.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiron_nodes as pn\n",
    "\n",
    "\n",
    "@as_function_node\n",
    "def InputNode(structure=None):\n",
    "    return structure\n",
    "\n",
    "\n",
    "@as_function_node\n",
    "def OutputNode(structure=None):\n",
    "    return structure\n",
    "\n",
    "InputStructure = \"va_i_subgraph__structure\"\n",
    "OutputStructure = \"va_o_subgraph__structure\"\n",
    "\n",
    "sub_graph = base.Graph(label=\"subgraph\")\n",
    "sub_graph += InputNode(label=InputStructure)\n",
    "#sub_graph += pn.atomistic.structure.transform.Repeat(label=\"Repeat\")\n",
    "#sub_graph += pn.atomistic.structure.transform.Repeat(label=\"Repeat_2\")\n",
    "#sub_graph += pn.atomistic.structure.view.Plot3d(label=\"Plot3d\")\n",
    "sub_graph += OutputNode(label=OutputStructure)\n",
    "\n",
    "#sub_graph += base.GraphEdge(\"Repeat\", \"Repeat_2\", \"structure\", \"structure\")\n",
    "#sub_graph += base.GraphEdge(InputStructure, \"Repeat\", \"structure\", \"structure\")\n",
    "#sub_graph += base.GraphEdge(InputStructure, \"Plot3d\", \"structure\", \"structure\")\n",
    "#sub_graph += base.GraphEdge(\"Repeat_2\", OutputStructure, \"structure\", \"structure\")\n",
    "\n",
    "graph = base.Graph(label=\"Workflow\")\n",
    "graph += pn.atomistic.structure.build.Bulk(name=\"Al\", label=\"structure\")\n",
    "graph += pn.atomistic.structure.transform.Repeat(label=\"repeat\")\n",
    "graph += sub_graph\n",
    "graph.nodes[\"subgraph\"].expanded = False\n",
    "graph.nodes[\"subgraph\"].node = base.graph_to_node(sub_graph)\n",
    "\n",
    "graph += pn.atomistic.structure.view.Plot3d(label=\"plot\")\n",
    "\n",
    "graph += base.GraphEdge(\"structure\", \"repeat\", \"structure\", \"structure\")\n",
    "graph += base.GraphEdge(OutputStructure, \"plot\", \"structure\", \"structure\")\n",
    "graph += base.GraphEdge(\"repeat\", InputStructure, \"structure\", \"structure\")\n",
    "# graph += base.GraphEdge(\"subgraph\", \"plot\", \"structure\", \"structure\")\n",
    "# graph += base.GraphEdge(\"repeat\", \"subgraph\", \"structure\", \"structure\")\n",
    "\n",
    "graph = base.remove_node(graph, \"Repeat\")\n",
    "graph = base.remove_node(graph, \"Repeat_2\")\n",
    "\n",
    "\n",
    "base.GuiGraph(graph);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graph = base.Graph(label=\"subgraph\")\n",
    "sub_graph += pn.atomistic.structure.build.Bulk(label='Bulk', name='Al')\n",
    "sub_graph += pn.atomistic.structure.transform.Repeat(label=\"Repeat\", repeat_scalar=2)\n",
    "sub_graph += pn.atomistic.structure.transform.Repeat(label=\"Repeat_2\")\n",
    "sub_graph += pn.atomistic.structure.view.Plot3d(label=\"Plot3d\")\n",
    "# sub_graph += OutputNode(label=OutputStructure)\n",
    "\n",
    "sub_graph += base.GraphEdge(\"Repeat\", \"Repeat_2\", \"structure\", \"structure\")\n",
    "sub_graph += base.GraphEdge(\"Bulk\", \"Repeat\", \"structure\", \"structure\")\n",
    "sub_graph += base.GraphEdge(\"Bulk\", \"Plot3d\", \"structure\", \"structure\")\n",
    "# sub_graph += base.GraphEdge(\"Repeat_2\", OutputStructure, \"structure\", \"structure\")\n",
    "\n",
    "# sub_graph = base.update_execution_graph(sub_graph)\n",
    "\n",
    "graph = base.Graph(label=\"Workflow\")\n",
    "graph += pn.atomistic.structure.build.Bulk(name=\"Al\", label=\"structure\")\n",
    "graph += pn.atomistic.structure.transform.Repeat(label=\"repeat\")\n",
    "# graph += base.graph_to_node(sub_graph)\n",
    "graph += sub_graph \n",
    "graph.nodes[\"subgraph\"].expanded = False\n",
    "graph.nodes[\"subgraph\"].node = base.graph_to_node(sub_graph)\n",
    "\n",
    "graph += pn.atomistic.structure.view.Plot3d(label=\"plot\")\n",
    "\n",
    "graph += base.GraphEdge(\"structure\", \"repeat\", \"structure\", \"structure\")\n",
    "# graph += base.GraphEdge(OutputStructure, \"plot\", \"structure\", \"structure\")\n",
    "# graph += base.GraphEdge(\"repeat\", InputStructure, \"structure\", \"structure\")\n",
    "\n",
    "base.get_inputs_of_graph(sub_graph, exclude_unconnected_default_ports=True)\n",
    "base.GuiGraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = base.graph_to_node(sub_graph)\n",
    "node.inputs.repeat_scalar = 1\n",
    "node.inputs\n",
    "\n",
    "node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes[\"subgraph\"].expanded = True\n",
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.nodes[\"subgraph\"].expanded)\n",
    "# Collapse a node\n",
    "collapsed_graph = base.collapse_node(graph, \"subgraph\")\n",
    "\n",
    "# Expand a node\n",
    "expanded_graph = base._expand_node(graph, \"subgraph\")\n",
    "print(graph.nodes[\"subgraph\"].expanded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow([graph])\n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.GuiGraph(collapsed_graph);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes[\"subgraph\"].node.__getstate__() # correct function has to be constructed and stored in the node!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow('lammps_full')\n",
    "\n",
    "# wf.structure = pn.atomistic.structure.build.Bulk('Al', cubic=True)\n",
    "wf.lammps = pn.atomistic.engine.lammps.Code1() # structure=wf.structure)\n",
    "# wf.md_output = pn.atomistic.calculator.data.OutputCalcMD(dataclass=wf.lammps.outputs.generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = base.Graph(label='test')\n",
    "graph += pn.atomistic.engine.lammps.Code1()\n",
    "graph.nodes[\"Code1\"].expanded = False\n",
    "\n",
    "base.GuiGraph(graph)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.nodes['Code1'].graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = base.get_full_graph_from_wf(wf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.get_import_path_from_type(pn.atomistic.engine.lammps.Code1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wf = Workflow(\"flow\")\n",
    "# wf.LoadGraph = pn.graphs.flow.LoadGraph('lammps_full')\n",
    "# wf.DisplayNodes = pn.graphs.flow.DisplayNodes(graph=wf.LoadGraph)\n",
    "# wf.DisplayNodes.pull()\n",
    "\n",
    "# graph = base.get_full_graph_from_wf(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base.GuiGraph(pf.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = gui.PyironFlow([wf, 'flow_expand', 'edges', 'iterCellSize'])\n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import as_macro_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = base.Graph('test')\n",
    "graph += pf.graph.nodes['Repeat']\n",
    "\n",
    "pf.graph.nodes['Repeat'].node.outputs.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.get_inputs_of_graph(pf.graph, exclude_unconnected_default_ports=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.get_inputs_of_graph(graph, exclude_unconnected_default_ports=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.get_outputs_of_graph(pf.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base.graph_to_code(pf.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = base.graph_to_node(pf.graph, exclude_unconnected_default_ports=False)\n",
    "node.inputs.repeat_scalar = 1\n",
    "node.run()\n",
    "node.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "inspect.getsource(node._func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "from functools import partial\n",
    "\n",
    "def graph_to_code(graph):\n",
    "    graph = base.get_updated_graph(graph)\n",
    "    graph = base.topological_sort(graph)\n",
    "    graph = base.get_code_from_graph(graph)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def graph_to_node(graph: base.Graph, exclude_unconnected_default_ports=True) -> base.Node:\n",
    "    \n",
    "    function_string = graph_to_code(graph)\n",
    "    \n",
    "    # Create a dictionary to serve as the local namespace\n",
    "    virtual_namespace = {}\n",
    "    \n",
    "    # Execute the function string in the local namespace\n",
    "    exec(function_string, globals(), virtual_namespace)\n",
    "    \n",
    "    # Retrieve the function from the local namespace\n",
    "    func = virtual_namespace[graph.label]\n",
    "\n",
    "    node = base.Node(\n",
    "        func=func,\n",
    "        label=graph.label,\n",
    "        node_type=\"graph\",\n",
    "        inputs=base.get_inputs_of_graph(graph, exclude_unconnected_default_ports=True),\n",
    "        outputs=base.get_outputs_of_graph(graph),\n",
    "    )\n",
    "    node.label = graph.label  # should not be necessary\n",
    "\n",
    "\n",
    "    def _run(node):\n",
    "        port = func(**node.kwargs)\n",
    "\n",
    "        return port.node._workflow.run()\n",
    "    \n",
    "    node._run = types.MethodType(_run, node)\n",
    "\n",
    "    return node\n",
    "\n",
    "\n",
    "\n",
    "node = graph_to_node(pf.graph)\n",
    "node.inputs.repeat_scalar = 1\n",
    "\n",
    "node.run()\n",
    "node.outputs.structure.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "function_string = graph_to_code(pf.graph)\n",
    "\n",
    "# Create a dictionary to serve as the local namespace\n",
    "virtual_namespace = {}\n",
    "\n",
    "# Execute the function string in the local namespace\n",
    "exec(function_string, globals(), virtual_namespace)\n",
    "\n",
    "# Retrieve the function from the local namespace\n",
    "func = virtual_namespace['Workflow_3']\n",
    "\n",
    "port = func(name='Fe', repeat_scalar=2)\n",
    "port.node._workflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function as a string\n",
    "function_string = \"\"\"\n",
    "def Workflow_3(name: str, cubic: bool = False, repeat_scalar: int = 1):\n",
    "\n",
    "    from pyiron_workflow import Workflow\n",
    "    import pyiron_nodes\n",
    "\n",
    "    wf = Workflow('Workflow_3')\n",
    "\n",
    "    wf.Bulk = pyiron_nodes.atomistic.structure.build.Bulk(name=name, cubic=cubic) \n",
    "    wf.Repeat = pyiron_nodes.atomistic.structure.transform.Repeat(structure=wf.Bulk, repeat_scalar=repeat_scalar) \n",
    "\n",
    "    return wf.Repeat.outputs.structure\n",
    "\"\"\"\n",
    "\n",
    "# Create a dictionary to serve as the local namespace\n",
    "virtual_namespace = {}\n",
    "\n",
    "# Execute the function string in the local namespace\n",
    "exec(function_string, globals(), virtual_namespace)\n",
    "\n",
    "# Retrieve the function from the local namespace\n",
    "func = virtual_namespace['Workflow_3']\n",
    "\n",
    "port = func(name='Fe', repeat_scalar=2)\n",
    "port.node._workflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'lammps'\n",
    "print(graph.nodes[label].expanded)\n",
    "# Collapse a node\n",
    "collapsed_graph = base.collapse_node(graph, label)\n",
    "print(graph.nodes[label].expanded)\n",
    "\n",
    "# Expand a node\n",
    "expanded_graph = base.expand_node(graph, label)\n",
    "print(graph.nodes[label].expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.GuiGraph(collapsed_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.GuiGraph(expanded_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.GuiGraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes['lammps'].expanded = False\n",
    "\n",
    "u_graph = base.get_updated_graph(graph)\n",
    "\n",
    "graph.nodes['lammps'].expanded \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.GuiGraph(u_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
